{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-30T06:14:29.434666Z","iopub.execute_input":"2023-08-30T06:14:29.435922Z","iopub.status.idle":"2023-08-30T06:14:29.481227Z","shell.execute_reply.started":"2023-08-30T06:14:29.435867Z","shell.execute_reply":"2023-08-30T06:14:29.479963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing necessary libraries","metadata":{}},{"cell_type":"code","source":"#pip install --upgrade scikit-learnA","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:29.482859Z","iopub.execute_input":"2023-08-30T06:14:29.483670Z","iopub.status.idle":"2023-08-30T06:14:29.489216Z","shell.execute_reply.started":"2023-08-30T06:14:29.483618Z","shell.execute_reply":"2023-08-30T06:14:29.487870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport re\nimport string\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.impute import KNNImputer\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:29.491012Z","iopub.execute_input":"2023-08-30T06:14:29.491513Z","iopub.status.idle":"2023-08-30T06:14:31.949284Z","shell.execute_reply.started":"2023-08-30T06:14:29.491473Z","shell.execute_reply":"2023-08-30T06:14:31.948086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the data","metadata":{}},{"cell_type":"code","source":"movies_data = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/movies.csv')\nsample_data = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/sample.csv')\ntest = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv')\ntrain = pd.read_csv('/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:31.951812Z","iopub.execute_input":"2023-08-30T06:14:31.952711Z","iopub.status.idle":"2023-08-30T06:14:34.418265Z","shell.execute_reply.started":"2023-08-30T06:14:31.952669Z","shell.execute_reply":"2023-08-30T06:14:34.416996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating copies of the data for further manipulation","metadata":{}},{"cell_type":"code","source":"movie_copy = movies_data \ntest_copy = test \ntrain_copy = train","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:34.419742Z","iopub.execute_input":"2023-08-30T06:14:34.420075Z","iopub.status.idle":"2023-08-30T06:14:34.425257Z","shell.execute_reply.started":"2023-08-30T06:14:34.420046Z","shell.execute_reply":"2023-08-30T06:14:34.424111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Movies_data","metadata":{}},{"cell_type":"markdown","source":"### Let us look at the movies dataset first","metadata":{}},{"cell_type":"code","source":"movie_copy.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:34.427144Z","iopub.execute_input":"2023-08-30T06:14:34.427535Z","iopub.status.idle":"2023-08-30T06:14:34.502607Z","shell.execute_reply.started":"2023-08-30T06:14:34.427504Z","shell.execute_reply":"2023-08-30T06:14:34.501564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_copy.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:34.503959Z","iopub.execute_input":"2023-08-30T06:14:34.504312Z","iopub.status.idle":"2023-08-30T06:14:35.033564Z","shell.execute_reply.started":"2023-08-30T06:14:34.504283Z","shell.execute_reply":"2023-08-30T06:14:35.031984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_copy.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:35.034920Z","iopub.execute_input":"2023-08-30T06:14:35.035257Z","iopub.status.idle":"2023-08-30T06:14:35.536796Z","shell.execute_reply.started":"2023-08-30T06:14:35.035228Z","shell.execute_reply":"2023-08-30T06:14:35.535409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We observe over here that the columns : **'rating','ratingContents','releaseDateTheaters','boxOffice','distributor','soundType'** have over **1,00,000 null values**. Imputing these values to train our model will lead to biased predictions as majority of the data will be synthetic data. Hence we will **drop** these columns","metadata":{}},{"cell_type":"code","source":"movies_duplicate = movie_copy.duplicated()\n\n# Get the rows that are duplicates\nduplicate_rows = movie_copy[movies_duplicate]\n\n# Display the duplicate rows\nduplicate_rows\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:35.538423Z","iopub.execute_input":"2023-08-30T06:14:35.538891Z","iopub.status.idle":"2023-08-30T06:14:35.931634Z","shell.execute_reply.started":"2023-08-30T06:14:35.538845Z","shell.execute_reply":"2023-08-30T06:14:35.930232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary of the movies dataset\n\n> The columns : **'rating','ratingContents','releaseDateTheaters','boxOffice','distributor','soundType'** have over **1,00,000** null values and imputing these columns might be a bad idea. \n\n> **Removing** them would be a better idea. \n\n\n> There are **1571 duplicate** entries in the dataset. ","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Data Analysis & Data pre-processing","metadata":{}},{"cell_type":"markdown","source":"## Train dataset","metadata":{}},{"cell_type":"markdown","source":"### Let us take a look at the train dataset","metadata":{}},{"cell_type":"code","source":"train_copy","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:35.937771Z","iopub.execute_input":"2023-08-30T06:14:35.938293Z","iopub.status.idle":"2023-08-30T06:14:35.963159Z","shell.execute_reply.started":"2023-08-30T06:14:35.938247Z","shell.execute_reply":"2023-08-30T06:14:35.961905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_copy.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:35.964525Z","iopub.execute_input":"2023-08-30T06:14:35.965181Z","iopub.status.idle":"2023-08-30T06:14:36.204749Z","shell.execute_reply.started":"2023-08-30T06:14:35.965146Z","shell.execute_reply":"2023-08-30T06:14:36.202571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_copy.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:36.206229Z","iopub.execute_input":"2023-08-30T06:14:36.206613Z","iopub.status.idle":"2023-08-30T06:14:36.589135Z","shell.execute_reply.started":"2023-08-30T06:14:36.206580Z","shell.execute_reply":"2023-08-30T06:14:36.587872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- From the above, we see that we have a total of **162758** entries in train data.\n- There are **16812** unique **movieid**.\n- There are **4482** unique **reviewerName**.\n","metadata":{}},{"cell_type":"code","source":"train['sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:36.590714Z","iopub.execute_input":"2023-08-30T06:14:36.591191Z","iopub.status.idle":"2023-08-30T06:14:36.624605Z","shell.execute_reply.started":"2023-08-30T06:14:36.591149Z","shell.execute_reply":"2023-08-30T06:14:36.623255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_train = train_copy.isna().sum()\nmissing_train","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:36.626287Z","iopub.execute_input":"2023-08-30T06:14:36.626775Z","iopub.status.idle":"2023-08-30T06:14:36.868464Z","shell.execute_reply.started":"2023-08-30T06:14:36.626727Z","shell.execute_reply":"2023-08-30T06:14:36.867082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We see that there are **6447** null entries in our train dataset. This is a thing of concern for us and we need to find a way to combat these","metadata":{}},{"cell_type":"code","source":"missing_train_percent = missing_train/len(train)*100\n\nprint(\"Hence we see that the percentage of missing train['reviewText'] data  is:\",missing_train_percent['reviewText'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:36.870410Z","iopub.execute_input":"2023-08-30T06:14:36.871217Z","iopub.status.idle":"2023-08-30T06:14:36.881301Z","shell.execute_reply.started":"2023-08-30T06:14:36.871171Z","shell.execute_reply":"2023-08-30T06:14:36.880035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reviewer_counts=train_copy[train_copy['isFrequentReviewer'] == True]['reviewerName'].value_counts()\nreviewer_counts","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:36.883515Z","iopub.execute_input":"2023-08-30T06:14:36.884676Z","iopub.status.idle":"2023-08-30T06:14:36.920160Z","shell.execute_reply.started":"2023-08-30T06:14:36.884622Z","shell.execute_reply":"2023-08-30T06:14:36.919252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The above result tells us that we have **John Luna** who has reviewed the most, followed by **Bryan Phillips**","metadata":{}},{"cell_type":"code","source":"# Selecting the top 10 reviewers\ntop_10_reviewers = reviewer_counts.head(10)\n\n# Creating the bar plot\nplt.figure(figsize=(10, 6))\nplt.bar(top_10_reviewers.index, top_10_reviewers.values, color='skyblue')\nplt.xticks(rotation=90)  # Rotating x-axis labels for better readability\nplt.xlabel('Reviewer Name')\nplt.ylabel('Number of Reviews')\nplt.title('Top 10 Frequent Reviewers by Number of Reviews')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:36.921581Z","iopub.execute_input":"2023-08-30T06:14:36.922274Z","iopub.status.idle":"2023-08-30T06:14:37.457803Z","shell.execute_reply.started":"2023-08-30T06:14:36.922238Z","shell.execute_reply":"2023-08-30T06:14:37.456636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can see above the list of the 10 most frequent reviewers.","metadata":{}},{"cell_type":"code","source":"# Now let us look at the imbalance in the sentiment if there's any present\n\nsentiment_count = train_copy['sentiment'].value_counts()\nsentiment_count","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:37.459878Z","iopub.execute_input":"2023-08-30T06:14:37.460895Z","iopub.status.idle":"2023-08-30T06:14:37.498097Z","shell.execute_reply.started":"2023-08-30T06:14:37.460844Z","shell.execute_reply":"2023-08-30T06:14:37.496701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment_percent = sentiment_count/len(train) * 100\nsentiment_percent","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:37.500215Z","iopub.execute_input":"2023-08-30T06:14:37.501150Z","iopub.status.idle":"2023-08-30T06:14:37.513972Z","shell.execute_reply.started":"2023-08-30T06:14:37.501093Z","shell.execute_reply":"2023-08-30T06:14:37.512334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_percentage = 66.823751\nnegative_percentage = 33.176249\n\n# Data for the pie chart\nlabels = ['Positive', 'Negative']\nsizes = [positive_percentage, negative_percentage]\ncolors = ['skyblue', 'lightcoral']\n\n# Create the pie chart without explode and shadow\nplt.figure(figsize=(6, 6))\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nplt.title('Sentiment Distribution')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:37.516536Z","iopub.execute_input":"2023-08-30T06:14:37.517035Z","iopub.status.idle":"2023-08-30T06:14:37.734572Z","shell.execute_reply.started":"2023-08-30T06:14:37.516990Z","shell.execute_reply":"2023-08-30T06:14:37.733457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There's almost twice as much of POSTIVE sentimented reviews versus NEGATIVE sentimented reviews. This suggests class imbalance. \n- Applying class imbalance techniques like **SMOTE, RandomOverSampler, RandomUnderSampler or ADYSN** might be a good idea.","metadata":{"execution":{"iopub.status.busy":"2023-07-28T19:44:31.106762Z","iopub.execute_input":"2023-07-28T19:44:31.107115Z","iopub.status.idle":"2023-07-28T19:44:31.114362Z","shell.execute_reply.started":"2023-07-28T19:44:31.107089Z","shell.execute_reply":"2023-07-28T19:44:31.113196Z"}}},{"cell_type":"markdown","source":"# Summary of Train dataset\n\n> We have a total of **162758** entries in train dataset. Of these, there are **16812** unique **movieid** and there are **4482** unique reviewerName.\n\n> About **3.9610 %** of reviewName column has null values.\n\n> **John Luna** has reviewed the most, followed by **Bryan Phillips**\n\n> The train dataset is **imbalanced** with **66.823751% Positive** sentiment reviews and **33.176249% Negative** sentimented reviews","metadata":{}},{"cell_type":"markdown","source":"## Test data","metadata":{}},{"cell_type":"markdown","source":"### Let us take a look at the train dataset","metadata":{}},{"cell_type":"code","source":"# A look at the test data\n\ntest_copy","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:37.736484Z","iopub.execute_input":"2023-08-30T06:14:37.737172Z","iopub.status.idle":"2023-08-30T06:14:37.757926Z","shell.execute_reply.started":"2023-08-30T06:14:37.737132Z","shell.execute_reply":"2023-08-30T06:14:37.756723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Shape of the test data is **(55315,4)**","metadata":{}},{"cell_type":"code","source":"missing_test = test_copy.isna().sum()\nmissing_test","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:37.759777Z","iopub.execute_input":"2023-08-30T06:14:37.760578Z","iopub.status.idle":"2023-08-30T06:14:37.840539Z","shell.execute_reply.started":"2023-08-30T06:14:37.760527Z","shell.execute_reply":"2023-08-30T06:14:37.839201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_test_percent = missing_test/len(train)*100\n\nprint(\"Hence we see that the percentage of missing test['reviewText'] data  is:\",missing_test_percent['reviewText'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:37.842110Z","iopub.execute_input":"2023-08-30T06:14:37.842858Z","iopub.status.idle":"2023-08-30T06:14:37.850188Z","shell.execute_reply.started":"2023-08-30T06:14:37.842817Z","shell.execute_reply":"2023-08-30T06:14:37.848870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary of Test dataset\n\n> The dataset has a shape of **(55315,4)**.\n\n> About **2510** entries or **1.542%** of reviewName column has null values.","metadata":{}},{"cell_type":"markdown","source":"## Data Pre-processing","metadata":{}},{"cell_type":"code","source":"#Initially we will encode the sentiment column in train dataset\n\nlabel_encoder = LabelEncoder()\ntrain_copy['sentiment'] = label_encoder.fit_transform(train_copy['sentiment'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:37.851889Z","iopub.execute_input":"2023-08-30T06:14:37.852799Z","iopub.status.idle":"2023-08-30T06:14:37.945762Z","shell.execute_reply.started":"2023-08-30T06:14:37.852760Z","shell.execute_reply":"2023-08-30T06:14:37.944538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_copy['isFrequentReviewer'] = label_encoder.fit_transform(train_copy['isFrequentReviewer'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:37.947188Z","iopub.execute_input":"2023-08-30T06:14:37.948072Z","iopub.status.idle":"2023-08-30T06:14:37.961475Z","shell.execute_reply.started":"2023-08-30T06:14:37.948023Z","shell.execute_reply":"2023-08-30T06:14:37.960128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filling in the missing values\n\ntrain_copy['reviewText'].fillna('missing', inplace=True)\ntrain_copy.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:37.963034Z","iopub.execute_input":"2023-08-30T06:14:37.963697Z","iopub.status.idle":"2023-08-30T06:14:38.204556Z","shell.execute_reply.started":"2023-08-30T06:14:37.963661Z","shell.execute_reply":"2023-08-30T06:14:38.203427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We see there are no missing values in our train dataset now. Similarly we will do this for our test dataset","metadata":{}},{"cell_type":"code","source":"# Applying similar techniques for the test dataset\n\ntest_copy['reviewText'].fillna('missing', inplace=True)\ntest_copy.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:38.206040Z","iopub.execute_input":"2023-08-30T06:14:38.207561Z","iopub.status.idle":"2023-08-30T06:14:38.298127Z","shell.execute_reply.started":"2023-08-30T06:14:38.207519Z","shell.execute_reply":"2023-08-30T06:14:38.297193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre-processing Functions","metadata":{}},{"cell_type":"markdown","source":"#### Let us define some functions to clean up our reviewText column","metadata":{}},{"cell_type":"markdown","source":"___________________________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"code","source":"import re\n\n# Function to cleanup the review column to prepare it for modeling\ndef clean_review(review):\n    # Convert the review to lowercase\n    review = str(review).lower()\n    \n    # Remove URLs\n    review = re.sub(r'https?://\\S+', '', review)\n    \n    # Remove HTML tags\n    review = re.sub(r'<[^>]*>', '', review)\n    \n    # Remove newlines\n    review = re.sub('\\n', ' ', review)\n    \n    # Remove alphanumeric words and single letters\n    review = re.sub(r'\\b\\w\\b', '', review)\n    \n    # Remove punctuation, excluding specific characters\n    review = re.sub(r'[^\\w\\s!@$%^&*(),.?\":{}|<>]', '', review)\n    \n    # Remove numbers and apostrophes\n    review = re.sub(r'\\b\\d+\\b', '', review)\n    review = re.sub(r\"'\", '', review)\n\n    return review\n\n\n# For train DataFrame\ntrain_copy['reviewText'] = train_copy['reviewText'].apply(lambda x: clean_review(x))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:38.308444Z","iopub.execute_input":"2023-08-30T06:14:38.309497Z","iopub.status.idle":"2023-08-30T06:14:43.677108Z","shell.execute_reply.started":"2023-08-30T06:14:38.309441Z","shell.execute_reply":"2023-08-30T06:14:43.675990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to remove stop words from the reviewText column\n\nstop_words = [\"0o\",\"0s\",\"3a\",\"3b\",\"3d\",\"6b\",\"6o\",\"a\",\"a1\",\"a2\",\"a3\",\"a4\",\"ab\",\"able\",\"about\",\"above\",\"abst\",\"ac\",\"accordance\",\"according\",\"accordingly\",\"across\",\"act\",\"actually\",\"ad\",\"added\",\"adj\",\"ae\",\"af\",\"affected\",\"affecting\",\"affects\",\"after\",\"afterwards\",\"ag\",\"again\",\"against\",\"ah\",\"ain\",\"ain't\",\"aj\",\"al\",\"all\",\"allow\",\"allows\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"am\",\"among\",\"amongst\",\"amoungst\",\"amount\",\"an\",\"and\",\"announce\",\"another\",\"any\",\"anybody\",\"anyhow\",\"anymore\",\"anyone\",\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"ao\",\"ap\",\"apart\",\"apparently\",\"appear\",\"appreciate\",\"appropriate\",\"approximately\",\"ar\",\"are\",\"aren\",\"arent\",\"aren't\",\"arise\",\"around\",\"as\",\"a's\",\"aside\",\"ask\",\"asking\",\"associated\",\"at\",\"au\",\"auth\",\"av\",\"available\",\"aw\",\"away\",\"awfully\",\"ax\",\"ay\",\"az\",\"b\",\"b1\",\"b2\",\"b3\",\"ba\",\"back\",\"bc\",\"bd\",\"be\",\"became\",\"because\",\"become\",\"becomes\",\"becoming\",\"been\",\"before\",\"beforehand\",\"begin\",\"beginning\",\"beginnings\",\"begins\",\"behind\",\"being\",\"believe\",\"below\",\"beside\",\"besides\",\"best\",\"better\",\"between\",\"beyond\",\"bi\",\"bill\",\"biol\",\"bj\",\"bk\",\"bl\",\"bn\",\"both\",\"bottom\",\"bp\",\"br\",\"brief\",\"briefly\",\"bs\",\"bt\",\"bu\",\"but\",\"bx\",\"by\",\"c\",\"c1\",\"c2\",\"c3\",\"ca\",\"call\",\"came\",\"can\",\"cannot\",\"cant\",\"can't\",\"cause\",\"causes\",\"cc\",\"cd\",\"ce\",\"certain\",\"certainly\",\"cf\",\"cg\",\"ch\",\"changes\",\"ci\",\"cit\",\"cj\",\"cl\",\"clearly\",\"cm\",\"c'mon\",\"cn\",\"co\",\"com\",\"come\",\"comes\",\"con\",\"concerning\",\"consequently\",\"consider\",\"considering\",\"contain\",\"containing\",\"contains\",\"corresponding\",\"could\",\"couldn\",\"couldnt\",\"couldn't\",\"course\",\"cp\",\"cq\",\"cr\",\"cry\",\"cs\",\"c's\",\"ct\",\"cu\",\"currently\",\"cv\",\"cx\",\"cy\",\"cz\",\"d\",\"d2\",\"da\",\"date\",\"dc\",\"dd\",\"de\",\"definitely\",\"describe\",\"described\",\"despite\",\"detail\",\"df\",\"di\",\"did\",\"didn\",\"didn't\",\"different\",\"dj\",\"dk\",\"dl\",\"do\",\"does\",\"doesn\",\"doesn't\",\"doing\",\"don\",\"done\",\"don't\",\"down\",\"downwards\",\"dp\",\"dr\",\"ds\",\"dt\",\"du\",\"due\",\"during\",\"dx\",\"dy\",\"e\",\"e2\",\"e3\",\"ea\",\"each\",\"ec\",\"ed\",\"edu\",\"ee\",\"ef\",\"effect\",\"eg\",\"ei\",\"eight\",\"eighty\",\"either\",\"ej\",\"el\",\"eleven\",\"else\",\"elsewhere\",\"em\",\"empty\",\"en\",\"end\",\"ending\",\"enough\",\"entirely\",\"eo\",\"ep\",\"eq\",\"er\",\"es\",\"especially\",\"est\",\"et\",\"et-al\",\"etc\",\"eu\",\"ev\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\"exactly\",\"example\",\"except\",\"ey\",\"f\",\"f2\",\"fa\",\"far\",\"fc\",\"few\",\"ff\",\"fi\",\"fifteen\",\"fifth\",\"fify\",\"fill\",\"find\",\"fire\",\"first\",\"five\",\"fix\",\"fj\",\"fl\",\"fn\",\"fo\",\"followed\",\"following\",\"follows\",\"for\",\"former\",\"formerly\",\"forth\",\"forty\",\"found\",\"four\",\"fr\",\"from\",\"front\",\"fs\",\"ft\",\"fu\",\"full\",\"further\",\"furthermore\",\"fy\",\"g\",\"ga\",\"gave\",\"ge\",\"get\",\"gets\",\"getting\",\"gi\",\"give\",\"given\",\"gives\",\"giving\",\"gj\",\"gl\",\"go\",\"goes\",\"going\",\"gone\",\"got\",\"gotten\",\"gr\",\"greetings\",\"gs\",\"gy\",\"h\",\"h2\",\"h3\",\"had\",\"hadn\",\"hadn't\",\"happens\",\"hardly\",\"has\",\"hasn\",\"hasnt\",\"hasn't\",\"have\",\"haven\",\"haven't\",\"having\",\"he\",\"hed\",\"he'd\",\"he'll\",\"hello\",\"help\",\"hence\",\"her\",\"here\",\"hereafter\",\"hereby\",\"herein\",\"heres\",\"here's\",\"hereupon\",\"hers\",\"herself\",\"hes\",\"he's\",\"hh\",\"hi\",\"hid\",\"him\",\"himself\",\"his\",\"hither\",\"hj\",\"ho\",\"home\",\"hopefully\",\"how\",\"howbeit\",\"however\",\"how's\",\"hr\",\"hs\",\"http\",\"hu\",\"hundred\",\"hy\",\"i\",\"i2\",\"i3\",\"i4\",\"i6\",\"i7\",\"i8\",\"ia\",\"ib\",\"ibid\",\"ic\",\"id\",\"i'd\",\"ie\",\"if\",\"ig\",\"ignored\",\"ih\",\"ii\",\"ij\",\"il\",\"i'll\",\"im\",\"i'm\",\"immediate\",\"immediately\",\"importance\",\"important\",\"in\",\"inasmuch\",\"inc\",\"indeed\",\"index\",\"indicate\",\"indicated\",\"indicates\",\"information\",\"inner\",\"insofar\",\"instead\",\"interest\",\"into\",\"invention\",\"inward\",\"io\",\"ip\",\"iq\",\"ir\",\"is\",\"isn\",\"isn't\",\"it\",\"itd\",\"it'd\",\"it'll\",\"its\",\"it's\",\"itself\",\"iv\",\"i've\",\"ix\",\"iy\",\"iz\",\"j\",\"jj\",\"jr\",\"js\",\"jt\",\"ju\",\"just\",\"k\",\"ke\",\"keep\",\"keeps\",\"kept\",\"kg\",\"kj\",\"km\",\"know\",\"known\",\"knows\",\"ko\",\"l\",\"l2\",\"la\",\"largely\",\"last\",\"lately\",\"later\",\"latter\",\"latterly\",\"lb\",\"lc\",\"le\",\"least\",\"les\",\"less\",\"lest\",\"let\",\"lets\",\"let's\",\"lf\",\"like\",\"liked\",\"likely\",\"line\",\"little\",\"lj\",\"ll\",\"ll\",\"ln\",\"lo\",\"look\",\"looking\",\"looks\",\"los\",\"lr\",\"ls\",\"lt\",\"ltd\",\"m\",\"m2\",\"ma\",\"made\",\"mainly\",\"make\",\"makes\",\"many\",\"may\",\"maybe\",\"me\",\"mean\",\"means\",\"meantime\",\"meanwhile\",\"merely\",\"mg\",\"might\",\"mightn\",\"mightn't\",\"mill\",\"million\",\"mine\",\"miss\",\"ml\",\"mn\",\"mo\",\"more\",\"moreover\",\"most\",\"mostly\",\"move\",\"mr\",\"mrs\",\"ms\",\"mt\",\"mu\",\"much\",\"mug\",\"must\",\"mustn\",\"mustn't\",\"my\",\"myself\",\"n\",\"n2\",\"na\",\"name\",\"namely\",\"nay\",\"nc\",\"nd\",\"ne\",\"near\",\"nearly\",\"necessarily\",\"necessary\",\"need\",\"needn\",\"needn't\",\"needs\",\"neither\",\"never\",\"nevertheless\",\"new\",\"next\",\"ng\",\"ni\",\"nine\",\"ninety\",\"nj\",\"nl\",\"nn\",\"no\",\"nobody\",\"non\",\"none\",\"nonetheless\",\"noone\",\"nor\",\"normally\",\"nos\",\"not\",\"noted\",\"nothing\",\"novel\",\"now\",\"nowhere\",\"nr\",\"ns\",\"nt\",\"ny\",\"o\",\"oa\",\"ob\",\"obtain\",\"obtained\",\"obviously\",\"oc\",\"od\",\"of\",\"off\",\"often\",\"og\",\"oh\",\"oi\",\"oj\",\"ok\",\"okay\",\"ol\",\"old\",\"om\",\"omitted\",\"on\",\"once\",\"one\",\"ones\",\"only\",\"onto\",\"oo\",\"op\",\"oq\",\"or\",\"ord\",\"os\",\"ot\",\"other\",\"others\",\"otherwise\",\"ou\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"outside\",\"over\",\"overall\",\"ow\",\"owing\",\"own\",\"ox\",\"oz\",\"p\",\"p1\",\"p2\",\"p3\",\"page\",\"pagecount\",\"pages\",\"par\",\"part\",\"particular\",\"particularly\",\"pas\",\"past\",\"pc\",\"pd\",\"pe\",\"per\",\"perhaps\",\"pf\",\"ph\",\"pi\",\"pj\",\"pk\",\"pl\",\"placed\",\"please\",\"plus\",\"pm\",\"pn\",\"po\",\"poorly\",\"possible\",\"possibly\",\"potentially\",\"pp\",\"pq\",\"pr\",\"predominantly\",\"present\",\"presumably\",\"previously\",\"primarily\",\"probably\",\"promptly\",\"proud\",\"provides\",\"ps\",\"pt\",\"pu\",\"put\",\"py\",\"q\",\"qj\",\"qu\",\"que\",\"quickly\",\"quite\",\"qv\",\"r\",\"r2\",\"ra\",\"ran\",\"rather\",\"rc\",\"rd\",\"re\",\"readily\",\"really\",\"reasonably\",\"recent\",\"recently\",\"ref\",\"refs\",\"regarding\",\"regardless\",\"regards\",\"related\",\"relatively\",\"research\",\"research-articl\",\"respectively\",\"resulted\",\"resulting\",\"results\",\"rf\",\"rh\",\"ri\",\"right\",\"rj\",\"rl\",\"rm\",\"rn\",\"ro\",\"rq\",\"rr\",\"rs\",\"rt\",\"ru\",\"run\",\"rv\",\"ry\",\"s\",\"s2\",\"sa\",\"said\",\"same\",\"saw\",\"say\",\"saying\",\"says\",\"sc\",\"sd\",\"se\",\"sec\",\"second\",\"secondly\",\"section\",\"see\",\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\"sensible\",\"sent\",\"serious\",\"seriously\",\"seven\",\"several\",\"sf\",\"shall\",\"shan\",\"shan't\",\"she\",\"shed\",\"she'd\",\"she'll\",\"shes\",\"she's\",\"should\",\"shouldn\",\"shouldn't\",\"should've\",\"show\",\"showed\",\"shown\",\"showns\",\"shows\",\"si\",\"side\",\"significant\",\"significantly\",\"similar\",\"similarly\",\"since\",\"sincere\",\"six\",\"sixty\",\"sj\",\"sl\",\"slightly\",\"sm\",\"sn\",\"so\",\"some\",\"somebody\",\"somehow\",\"someone\",\"somethan\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\"sp\",\"specifically\",\"specified\",\"specify\",\"specifying\",\"sq\",\"sr\",\"ss\",\"st\",\"still\",\"stop\",\"strongly\",\"sub\",\"substantially\",\"successfully\",\"such\",\"sufficiently\",\"suggest\",\"sup\",\"sure\",\"sy\",\"system\",\"sz\",\"t\",\"t1\",\"t2\",\"t3\",\"take\",\"taken\",\"taking\",\"tb\",\"tc\",\"td\",\"te\",\"tell\",\"ten\",\"tends\",\"tf\",\"th\",\"than\",\"thank\",\"thanks\",\"thanx\",\"that\",\"that'll\",\"thats\",\"that's\",\"that've\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"thence\",\"there\",\"thereafter\",\"thereby\",\"thered\",\"therefore\",\"therein\",\"there'll\",\"thereof\",\"therere\",\"theres\",\"there's\",\"thereto\",\"thereupon\",\"there've\",\"these\",\"they\",\"theyd\",\"they'd\",\"they'll\",\"theyre\",\"they're\",\"they've\",\"thickv\",\"thin\",\"think\",\"third\",\"this\",\"thorough\",\"thoroughly\",\"those\",\"thou\",\"though\",\"thoughh\",\"thousand\",\"three\",\"throug\",\"through\",\"throughout\",\"thru\",\"thus\",\"ti\",\"til\",\"tip\",\"tj\",\"tl\",\"tm\",\"tn\",\"to\",\"together\",\"too\",\"took\",\"top\",\"toward\",\"towards\",\"tp\",\"tq\",\"tr\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\"ts\",\"t's\",\"tt\",\"tv\",\"twelve\",\"twenty\",\"twice\",\"two\",\"tx\",\"u\",\"u201d\",\"ue\",\"ui\",\"uj\",\"uk\",\"um\",\"un\",\"under\",\"unfortunately\",\"unless\",\"unlike\",\"unlikely\",\"until\",\"unto\",\"uo\",\"up\",\"upon\",\"ups\",\"ur\",\"us\",\"use\",\"used\",\"useful\",\"usefully\",\"usefulness\",\"uses\",\"using\",\"usually\",\"ut\",\"v\",\"va\",\"value\",\"various\",\"vd\",\"ve\",\"ve\",\"very\",\"via\",\"viz\",\"vj\",\"vo\",\"vol\",\"vols\",\"volumtype\",\"vq\",\"vs\",\"vt\",\"vu\",\"w\",\"wa\",\"want\",\"wants\",\"was\",\"wasn\",\"wasnt\",\"wasn't\",\"way\",\"we\",\"wed\",\"we'd\",\"welcome\",\"well\",\"we'll\",\"well-b\",\"went\",\"were\",\"we're\",\"weren\",\"werent\",\"weren't\",\"we've\",\"what\",\"whatever\",\"what'll\",\"whats\",\"what's\",\"when\",\"whence\",\"whenever\",\"when's\",\"where\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\"wheres\",\"where's\",\"whereupon\",\"wherever\",\"whether\",\"which\",\"while\",\"whim\",\"whither\",\"who\",\"whod\",\"whoever\",\"whole\",\"who'll\",\"whom\",\"whomever\",\"whos\",\"who's\",\"whose\",\"why\",\"why's\",\"wi\",\"widely\",\"will\",\"willing\",\"wish\",\"with\",\"within\",\"without\",\"wo\",\"won\",\"wonder\",\"wont\",\"won't\",\"words\",\"world\",\"would\",\"wouldn\",\"wouldnt\",\"wouldn't\",\"www\",\"x\",\"x1\",\"x2\",\"x3\",\"xf\",\"xi\",\"xj\",\"xk\",\"xl\",\"xn\",\"xo\",\"xs\",\"xt\",\"xv\",\"xx\",\"y\",\"y2\",\"yes\",\"yet\",\"yj\",\"yl\",\"you\",\"youd\",\"you'd\",\"you'll\",\"your\",\"youre\",\"you're\",\"yours\",\"yourself\",\"yourselves\",\"you've\",\"yr\",\"ys\",\"yt\",\"z\",\"zero\",\"zi\",\"zz\"]\n\n\n# Define the function to remove stop words from a single review\ndef remove_stop_words_from_review(review, stop_words):\n    words = review.split()  # Tokenize the review into words\n    filtered_words = [word for word in words if word.lower() not in stop_words]  # Remove stop words\n    processed_review = ' '.join(filtered_words)  # Reconstruct the review without stop words\n    return processed_review","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:43.679036Z","iopub.execute_input":"2023-08-30T06:14:43.679416Z","iopub.status.idle":"2023-08-30T06:14:43.735155Z","shell.execute_reply.started":"2023-08-30T06:14:43.679361Z","shell.execute_reply":"2023-08-30T06:14:43.733878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_copy.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:43.737031Z","iopub.execute_input":"2023-08-30T06:14:43.737463Z","iopub.status.idle":"2023-08-30T06:14:43.756735Z","shell.execute_reply.started":"2023-08-30T06:14:43.737427Z","shell.execute_reply":"2023-08-30T06:14:43.755537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_copy['reviewText'] = train_copy['reviewText'].apply(lambda x: remove_stop_words_from_review(str(x), stop_words))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:14:43.758182Z","iopub.execute_input":"2023-08-30T06:14:43.758556Z","iopub.status.idle":"2023-08-30T06:15:31.120122Z","shell.execute_reply.started":"2023-08-30T06:14:43.758524Z","shell.execute_reply":"2023-08-30T06:15:31.118891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_copy","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:31.121961Z","iopub.execute_input":"2023-08-30T06:15:31.122334Z","iopub.status.idle":"2023-08-30T06:15:31.141832Z","shell.execute_reply.started":"2023-08-30T06:15:31.122302Z","shell.execute_reply":"2023-08-30T06:15:31.140450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"____________________________________","metadata":{}},{"cell_type":"code","source":"#Let us look at the duplicates present in the train data\n\ntrain_duplicate = train_copy[train_copy.duplicated(['movieid','reviewerName'],keep=False)]\n\ntrain_duplicate.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:31.143231Z","iopub.execute_input":"2023-08-30T06:15:31.143664Z","iopub.status.idle":"2023-08-30T06:15:31.248208Z","shell.execute_reply.started":"2023-08-30T06:15:31.143631Z","shell.execute_reply":"2023-08-30T06:15:31.246941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Grouping the duplicates together\n\ntrain_duplicate.groupby(['movieid']).count()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:31.249844Z","iopub.execute_input":"2023-08-30T06:15:31.250210Z","iopub.status.idle":"2023-08-30T06:15:31.272237Z","shell.execute_reply.started":"2023-08-30T06:15:31.250181Z","shell.execute_reply":"2023-08-30T06:15:31.270979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for the shapes of the sentiments of the duplicates\n\ntrain_duplicate[train_duplicate.sentiment == 1].shape, train_duplicate[train_duplicate.sentiment == 0].shape","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:31.273833Z","iopub.execute_input":"2023-08-30T06:15:31.274208Z","iopub.status.idle":"2023-08-30T06:15:31.284977Z","shell.execute_reply.started":"2023-08-30T06:15:31.274176Z","shell.execute_reply":"2023-08-30T06:15:31.283664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Let us clean up the test data now\n\ntest_copy['reviewText'] = test_copy['reviewText'].apply(lambda x: clean_review(x))\ntest_copy['reviewText'] = test_copy['reviewText'].apply(lambda x: remove_stop_words_from_review(str(x), stop_words))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:31.286338Z","iopub.execute_input":"2023-08-30T06:15:31.287129Z","iopub.status.idle":"2023-08-30T06:15:48.920719Z","shell.execute_reply.started":"2023-08-30T06:15:31.287082Z","shell.execute_reply":"2023-08-30T06:15:48.919518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_copy","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:48.922255Z","iopub.execute_input":"2023-08-30T06:15:48.922678Z","iopub.status.idle":"2023-08-30T06:15:48.938403Z","shell.execute_reply.started":"2023-08-30T06:15:48.922643Z","shell.execute_reply":"2023-08-30T06:15:48.937206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_copy['isTopCritic'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:48.939799Z","iopub.execute_input":"2023-08-30T06:15:48.940244Z","iopub.status.idle":"2023-08-30T06:15:48.960444Z","shell.execute_reply.started":"2023-08-30T06:15:48.940196Z","shell.execute_reply":"2023-08-30T06:15:48.959007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Encoding the isTopCritic column in test data\n\ntest_copy['isTopCritic'] = label_encoder.fit_transform(test_copy['isTopCritic'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:48.961976Z","iopub.execute_input":"2023-08-30T06:15:48.962334Z","iopub.status.idle":"2023-08-30T06:15:48.980415Z","shell.execute_reply.started":"2023-08-30T06:15:48.962305Z","shell.execute_reply":"2023-08-30T06:15:48.979211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Movies dataset- a recap","metadata":{}},{"cell_type":"code","source":"movie_copy.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:48.981645Z","iopub.execute_input":"2023-08-30T06:15:48.981984Z","iopub.status.idle":"2023-08-30T06:15:49.507510Z","shell.execute_reply.started":"2023-08-30T06:15:48.981957Z","shell.execute_reply":"2023-08-30T06:15:49.506245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to determine the total percentage of null values in a column\n\ndef null_value_percent(df):\n    percent = round(df.isnull().sum() / len(df) * 100, ndigits=2)\n    null_column_percent = pd.DataFrame(percent, columns=['Percent'])\n    return null_column_percent\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:49.508650Z","iopub.execute_input":"2023-08-30T06:15:49.509007Z","iopub.status.idle":"2023-08-30T06:15:49.517649Z","shell.execute_reply.started":"2023-08-30T06:15:49.508977Z","shell.execute_reply":"2023-08-30T06:15:49.515717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_value_percent(movie_copy)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:49.519494Z","iopub.execute_input":"2023-08-30T06:15:49.519882Z","iopub.status.idle":"2023-08-30T06:15:50.036350Z","shell.execute_reply.started":"2023-08-30T06:15:49.519851Z","shell.execute_reply":"2023-08-30T06:15:50.035106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We will drop the columns having null values above 50%","metadata":{}},{"cell_type":"code","source":"movie_copy.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:50.038014Z","iopub.execute_input":"2023-08-30T06:15:50.038660Z","iopub.status.idle":"2023-08-30T06:15:50.713397Z","shell.execute_reply.started":"2023-08-30T06:15:50.038620Z","shell.execute_reply":"2023-08-30T06:15:50.712071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_copy.movieid.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:50.714664Z","iopub.execute_input":"2023-08-30T06:15:50.715669Z","iopub.status.idle":"2023-08-30T06:15:50.870700Z","shell.execute_reply.started":"2023-08-30T06:15:50.715630Z","shell.execute_reply":"2023-08-30T06:15:50.869510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From a previous discussion, we see that some of the null values have over 50% of missing data. Therefore we will drop these columns.","metadata":{}},{"cell_type":"code","source":"drop_col = ['rating','ratingContents','releaseDateTheaters','boxOffice','distributor','soundType']\ndrop_movie = movie_copy.drop(columns = drop_col)\ndrop_movie.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:50.872267Z","iopub.execute_input":"2023-08-30T06:15:50.873280Z","iopub.status.idle":"2023-08-30T06:15:50.907590Z","shell.execute_reply.started":"2023-08-30T06:15:50.873234Z","shell.execute_reply":"2023-08-30T06:15:50.906198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_movie.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:50.909865Z","iopub.execute_input":"2023-08-30T06:15:50.910527Z","iopub.status.idle":"2023-08-30T06:15:50.920929Z","shell.execute_reply.started":"2023-08-30T06:15:50.910476Z","shell.execute_reply":"2023-08-30T06:15:50.919299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Next let us drop the duplicates from the movies data\nduplicate_movie = drop_movie.drop_duplicates('movieid')\nduplicate_movie","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:50.923216Z","iopub.execute_input":"2023-08-30T06:15:50.923727Z","iopub.status.idle":"2023-08-30T06:15:51.003161Z","shell.execute_reply.started":"2023-08-30T06:15:50.923683Z","shell.execute_reply":"2023-08-30T06:15:51.001347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merging train and movies dataset","metadata":{}},{"cell_type":"code","source":"merged_train_data = pd.merge(train_copy, duplicate_movie, on='movieid', how='inner')\nmerged_train_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:51.005315Z","iopub.execute_input":"2023-08-30T06:15:51.005954Z","iopub.status.idle":"2023-08-30T06:15:51.274342Z","shell.execute_reply.started":"2023-08-30T06:15:51.005919Z","shell.execute_reply":"2023-08-30T06:15:51.272346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:51.276489Z","iopub.execute_input":"2023-08-30T06:15:51.276984Z","iopub.status.idle":"2023-08-30T06:15:51.284870Z","shell.execute_reply.started":"2023-08-30T06:15:51.276948Z","shell.execute_reply":"2023-08-30T06:15:51.283595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_value_percent(merged_train_data)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:51.285919Z","iopub.execute_input":"2023-08-30T06:15:51.286271Z","iopub.status.idle":"2023-08-30T06:15:51.737023Z","shell.execute_reply.started":"2023-08-30T06:15:51.286239Z","shell.execute_reply":"2023-08-30T06:15:51.735913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Some columns still have null values and we need to fix them**","metadata":{}},{"cell_type":"code","source":"merged_train_data['audienceScore'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:51.738900Z","iopub.execute_input":"2023-08-30T06:15:51.739244Z","iopub.status.idle":"2023-08-30T06:15:51.746984Z","shell.execute_reply.started":"2023-08-30T06:15:51.739215Z","shell.execute_reply":"2023-08-30T06:15:51.745887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Functions for imputation and plotting a histogram","metadata":{}},{"cell_type":"markdown","source":"____________________________________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\ndef impute_column_with_median(data, column):\n    \n    # Create the SimpleImputer with the desired strategy and fill_value (median)\n    simple_imputer = SimpleImputer(strategy='median')\n    \n    # Reshape the column into a 2D array\n    column_2d = data[column].values.reshape(-1, 1)\n    \n    # Impute the missing values using SimpleImputer\n    imputed_column = simple_imputer.fit_transform(column_2d).flatten()\n    \n    # Update the DataFrame with the imputed column\n    data[column] = imputed_column\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:51.748498Z","iopub.execute_input":"2023-08-30T06:15:51.749208Z","iopub.status.idle":"2023-08-30T06:15:51.761809Z","shell.execute_reply.started":"2023-08-30T06:15:51.749166Z","shell.execute_reply":"2023-08-30T06:15:51.760704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def impute_column_with_most_frequent(data, column):\n    \n    # Create the SimpleImputer with the desired strategy (most_frequent)\n    simple_imputer = SimpleImputer(strategy='most_frequent')\n    \n    # Reshape the column into a 2D array\n    column_2d = data[column].values.reshape(-1, 1)\n    \n    # Impute the missing values using SimpleImputer\n    imputed_column = simple_imputer.fit_transform(column_2d).flatten()\n    \n    # Update the DataFrame with the imputed column\n    data[column] = imputed_column\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:51.763515Z","iopub.execute_input":"2023-08-30T06:15:51.763875Z","iopub.status.idle":"2023-08-30T06:15:51.775926Z","shell.execute_reply.started":"2023-08-30T06:15:51.763845Z","shell.execute_reply":"2023-08-30T06:15:51.774807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_histogram(data, column, bins=10, edgecolor='black'):\n    \n    # Extract the column data\n    column_data = data[column]\n\n    # Plot the distribution using a histogram\n    plt.hist(column_data, bins=bins, edgecolor=edgecolor)\n\n    # Set the labels and title\n    plt.xlabel(column)\n    plt.ylabel('Frequency')\n    plt.title(f'Distribution of {column}')\n\n    # Display the plot\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:51.777244Z","iopub.execute_input":"2023-08-30T06:15:51.777595Z","iopub.status.idle":"2023-08-30T06:15:51.788688Z","shell.execute_reply.started":"2023-08-30T06:15:51.777566Z","shell.execute_reply":"2023-08-30T06:15:51.787804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__________________________________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"code","source":"#Plotting the histogram before imputation for audienceScore\n\nplot_histogram(merged_train_data, 'audienceScore', bins=10, edgecolor='blue')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:51.789587Z","iopub.execute_input":"2023-08-30T06:15:51.789899Z","iopub.status.idle":"2023-08-30T06:15:52.063672Z","shell.execute_reply.started":"2023-08-30T06:15:51.789873Z","shell.execute_reply":"2023-08-30T06:15:52.062446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impute_column_with_median(merged_train_data, 'audienceScore')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:52.065588Z","iopub.execute_input":"2023-08-30T06:15:52.066039Z","iopub.status.idle":"2023-08-30T06:15:52.087269Z","shell.execute_reply.started":"2023-08-30T06:15:52.065997Z","shell.execute_reply":"2023-08-30T06:15:52.086141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the histogram after imputation for audienceScore\n\nplot_histogram(merged_train_data, 'audienceScore', bins=15, edgecolor='blue')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:52.089445Z","iopub.execute_input":"2023-08-30T06:15:52.089805Z","iopub.status.idle":"2023-08-30T06:15:52.349129Z","shell.execute_reply.started":"2023-08-30T06:15:52.089773Z","shell.execute_reply":"2023-08-30T06:15:52.347986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **We see that the distribution is maintained when using the median strategy except the fact that there is a spike at the median value**","metadata":{}},{"cell_type":"code","source":"null_value_percent(merged_train_data)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:52.350652Z","iopub.execute_input":"2023-08-30T06:15:52.351444Z","iopub.status.idle":"2023-08-30T06:15:52.793359Z","shell.execute_reply.started":"2023-08-30T06:15:52.351410Z","shell.execute_reply":"2023-08-30T06:15:52.791955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the histogram before imputation for runtimeMinutes\nplot_histogram(merged_train_data, 'runtimeMinutes', bins=10, edgecolor='green')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:52.795268Z","iopub.execute_input":"2023-08-30T06:15:52.795659Z","iopub.status.idle":"2023-08-30T06:15:53.119963Z","shell.execute_reply.started":"2023-08-30T06:15:52.795627Z","shell.execute_reply":"2023-08-30T06:15:53.118702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impute_column_with_median(merged_train_data, 'runtimeMinutes')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:53.121632Z","iopub.execute_input":"2023-08-30T06:15:53.122102Z","iopub.status.idle":"2023-08-30T06:15:53.144884Z","shell.execute_reply.started":"2023-08-30T06:15:53.122059Z","shell.execute_reply":"2023-08-30T06:15:53.143784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the histogram after imputation for runtimeMinutes\nplot_histogram(merged_train_data, 'runtimeMinutes', bins=10, edgecolor='green')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:53.146543Z","iopub.execute_input":"2023-08-30T06:15:53.146885Z","iopub.status.idle":"2023-08-30T06:15:53.471932Z","shell.execute_reply.started":"2023-08-30T06:15:53.146855Z","shell.execute_reply":"2023-08-30T06:15:53.470705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train_data.originalLanguage.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:53.473674Z","iopub.execute_input":"2023-08-30T06:15:53.474046Z","iopub.status.idle":"2023-08-30T06:15:53.507292Z","shell.execute_reply.started":"2023-08-30T06:15:53.474014Z","shell.execute_reply":"2023-08-30T06:15:53.506299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Before imputation\n\n# Get the value counts of each language\nlanguage_counts = merged_train_data['originalLanguage'].value_counts()\n\n# Extract the top 5 languages\ntop_5_languages = language_counts.head(5)\n\n# Plot the countplot for the top 5 languages\nplt.figure(figsize=(10, 6))  \nsns.countplot(y='originalLanguage', data=merged_train_data, order=top_5_languages.index)\n\n# Set the labels and title\nplt.xlabel('Count')\nplt.ylabel('Original Language')\nplt.title('Distribution of Top 5 Original Languages before imputation')\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:53.508531Z","iopub.execute_input":"2023-08-30T06:15:53.509457Z","iopub.status.idle":"2023-08-30T06:15:53.980048Z","shell.execute_reply.started":"2023-08-30T06:15:53.509418Z","shell.execute_reply":"2023-08-30T06:15:53.979064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impute_column_with_most_frequent(merged_train_data, 'originalLanguage')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:53.981463Z","iopub.execute_input":"2023-08-30T06:15:53.982363Z","iopub.status.idle":"2023-08-30T06:15:54.027192Z","shell.execute_reply.started":"2023-08-30T06:15:53.982327Z","shell.execute_reply":"2023-08-30T06:15:54.026242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After imputation\n\n# Get the value counts of each language\nlanguage_counts = merged_train_data['originalLanguage'].value_counts()\n\n# Extract the top 5 languages\ntop_5_languages = language_counts.head(5)\n\n# Plot the countplot for the top 5 languages\nplt.figure(figsize=(10, 6))  \nsns.countplot(y='originalLanguage', data=merged_train_data, order=top_5_languages.index)\n\n# Set the labels and title\nplt.xlabel('Count')\nplt.ylabel('Original Language')\nplt.title('Distribution of Top 5 Original Languages after imputation')\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:54.028671Z","iopub.execute_input":"2023-08-30T06:15:54.029347Z","iopub.status.idle":"2023-08-30T06:15:54.489838Z","shell.execute_reply.started":"2023-08-30T06:15:54.029309Z","shell.execute_reply":"2023-08-30T06:15:54.488674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The graph above tells us about the **top 5** most frequently occurring languages in the OriginalLanguages column which shows that most of the reviews are in **English**. The graph above is plotted after imputing the missing values with the most_frequent strategy.","metadata":{}},{"cell_type":"code","source":"merged_train_data.genre.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:54.491082Z","iopub.execute_input":"2023-08-30T06:15:54.491423Z","iopub.status.idle":"2023-08-30T06:15:54.527701Z","shell.execute_reply.started":"2023-08-30T06:15:54.491393Z","shell.execute_reply":"2023-08-30T06:15:54.526221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Before imputation\n\n# Get the value counts of each language\nlanguage_counts = merged_train_data['genre'].value_counts()\n\n# Extract the top 5 languages\ntop_5_languages = language_counts.head(5)\n\n# Plot the countplot for the top 5 languages\nplt.figure(figsize=(10, 6))  \nsns.countplot(y='genre', data=merged_train_data, order=top_5_languages.index)\n\n# Set the labels and title\nplt.xlabel('Count')\nplt.ylabel('Genre')\nplt.title('Distribution of Top 5 Genres before imputation')\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:54.529307Z","iopub.execute_input":"2023-08-30T06:15:54.530044Z","iopub.status.idle":"2023-08-30T06:15:54.991605Z","shell.execute_reply.started":"2023-08-30T06:15:54.530010Z","shell.execute_reply":"2023-08-30T06:15:54.990732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimpute_column_with_most_frequent(merged_train_data, 'genre')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:54.992885Z","iopub.execute_input":"2023-08-30T06:15:54.993850Z","iopub.status.idle":"2023-08-30T06:15:55.042345Z","shell.execute_reply.started":"2023-08-30T06:15:54.993811Z","shell.execute_reply":"2023-08-30T06:15:55.040723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After  imputation\n\n# Get the value counts of each language\nlanguage_counts = merged_train_data['genre'].value_counts()\n\n# Extract the top 5 languages\ntop_5_languages = language_counts.head(5)\n\n# Plot the countplot for the top 5 languages\nplt.figure(figsize=(10, 6))  \nsns.countplot(y='genre', data=merged_train_data, order=top_5_languages.index)\n\n# Set the labels and title\nplt.xlabel('Count')\nplt.ylabel('Genre')\nplt.title('Distribution of Top 5 Genres after imputation')\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:55.043887Z","iopub.execute_input":"2023-08-30T06:15:55.044370Z","iopub.status.idle":"2023-08-30T06:15:55.501046Z","shell.execute_reply.started":"2023-08-30T06:15:55.044326Z","shell.execute_reply":"2023-08-30T06:15:55.499935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train_data.releaseDateStreaming.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:55.502221Z","iopub.execute_input":"2023-08-30T06:15:55.502565Z","iopub.status.idle":"2023-08-30T06:15:55.540405Z","shell.execute_reply.started":"2023-08-30T06:15:55.502528Z","shell.execute_reply":"2023-08-30T06:15:55.538904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group the data by 'streaming_date' and count the number of movies on each date\nmovies_streamed_by_date = merged_train_data['movieid'].groupby(merged_train_data['releaseDateStreaming']).count()\n\n# Reset the index to convert the groupby result into a DataFrame\nmovies_streamed_by_date = movies_streamed_by_date.reset_index()\n\n# Sort the DataFrame by count of movies in descending order\nmovies_streamed_by_date_sorted = movies_streamed_by_date.sort_values(by='movieid', ascending=False)\n\n# Select the top 10 dates with the highest number of movies streamed\ntop_10_dates = movies_streamed_by_date_sorted.head(10)\n\n# Display the top 10 dates\nprint(top_10_dates)\n\n# Plot the line plot for the top 10 dates\nplt.figure(figsize=(12, 6))  # Adjust the figure size if needed for better visibility\nplt.plot(top_10_dates['releaseDateStreaming'], top_10_dates['movieid'], marker='o', linestyle='-', color='b')\n\n# Set the labels and title\nplt.xlabel('Streaming Date')\nplt.ylabel('Number of Movies Streamed')\nplt.title('Top 10 Dates with the Highest Number of Movies Streamed before imputation')\n\n# Rotate the x-axis labels for better readability\nplt.xticks(rotation=45)\n\n# Display the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:55.542281Z","iopub.execute_input":"2023-08-30T06:15:55.542824Z","iopub.status.idle":"2023-08-30T06:15:55.999726Z","shell.execute_reply.started":"2023-08-30T06:15:55.542773Z","shell.execute_reply":"2023-08-30T06:15:55.998281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impute_column_with_most_frequent(merged_train_data, 'releaseDateStreaming')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:56.001369Z","iopub.execute_input":"2023-08-30T06:15:56.001790Z","iopub.status.idle":"2023-08-30T06:15:56.047607Z","shell.execute_reply.started":"2023-08-30T06:15:56.001754Z","shell.execute_reply":"2023-08-30T06:15:56.046341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group the data by 'streaming_date' and count the number of movies on each date\nmovies_streamed_by_date = merged_train_data['movieid'].groupby(merged_train_data['releaseDateStreaming']).count()\n\n# Reset the index to convert the groupby result into a DataFrame\nmovies_streamed_by_date = movies_streamed_by_date.reset_index()\n\n# Sort the DataFrame by count of movies in descending order\nmovies_streamed_by_date_sorted = movies_streamed_by_date.sort_values(by='movieid', ascending=False)\n\n# Select the top 10 dates with the highest number of movies streamed\ntop_10_dates = movies_streamed_by_date_sorted.head(10)\n\n# Display the top 10 dates\nprint(top_10_dates)\n\n# Plot the line plot for the top 10 dates\nplt.figure(figsize=(12, 6))  # Adjust the figure size if needed for better visibility\nplt.plot(top_10_dates['releaseDateStreaming'], top_10_dates['movieid'], marker='o', linestyle='-', color='b')\n\n# Set the labels and title\nplt.xlabel('Streaming Date')\nplt.ylabel('Number of Movies Streamed')\nplt.title('Top 10 Dates with the Highest Number of Movies Streamed after imputation')\n\n# Rotate the x-axis labels for better readability\nplt.xticks(rotation=45)\n\n# Display the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:56.048608Z","iopub.execute_input":"2023-08-30T06:15:56.048932Z","iopub.status.idle":"2023-08-30T06:15:56.673497Z","shell.execute_reply.started":"2023-08-30T06:15:56.048905Z","shell.execute_reply":"2023-08-30T06:15:56.670624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_value_percent(merged_train_data)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:56.675595Z","iopub.execute_input":"2023-08-30T06:15:56.676095Z","iopub.status.idle":"2023-08-30T06:15:57.210695Z","shell.execute_reply.started":"2023-08-30T06:15:56.676049Z","shell.execute_reply":"2023-08-30T06:15:57.209486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_sentiment_count = merged_train_data['sentiment'].value_counts()\nmerged_sentiment_count\n\nmerged_sentiment_percent = merged_sentiment_count/len(merged_train_data) * 100\nmerged_sentiment_percent\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:57.212427Z","iopub.execute_input":"2023-08-30T06:15:57.213649Z","iopub.status.idle":"2023-08-30T06:15:57.227110Z","shell.execute_reply.started":"2023-08-30T06:15:57.213601Z","shell.execute_reply":"2023-08-30T06:15:57.225657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_percentage = 66.823751\nnegative_percentage = 33.176249\n\n# Data for the pie chart\nlabels = ['Positive', 'Negative']\nsizes = [positive_percentage, negative_percentage]\ncolors = ['skyblue', 'lightcoral']\n\n# Create the pie chart without explode and shadow\nplt.figure(figsize=(6, 6))\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nplt.title('Sentiment Distribution')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:57.229113Z","iopub.execute_input":"2023-08-30T06:15:57.230084Z","iopub.status.idle":"2023-08-30T06:15:57.408901Z","shell.execute_reply.started":"2023-08-30T06:15:57.230036Z","shell.execute_reply":"2023-08-30T06:15:57.407630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We notice the **imbalance is maintained** even in the merged training and movies dataset.","metadata":{}},{"cell_type":"markdown","source":"_______________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"markdown","source":"### Applying SMOTE to balance the merged movies and train dataset","metadata":{}},{"cell_type":"code","source":"# from sklearn.preprocessing import LabelEncoder\n# from imblearn.over_sampling import SMOTE\n\n# # Separate features and labels\n# features = merged_train_data.drop('sentiment', axis=1)\n# labels = merged_train_data['sentiment']\n\n# # Apply LabelEncoder to categorical features\n# label_encoders = {}\n# for column in features.select_dtypes(include=['object']).columns:\n#     le = LabelEncoder()\n#     features[column] = le.fit_transform(features[column])\n#     label_encoders[column] = le\n\n# # Apply SMOTE\n# smote = SMOTE(sampling_strategy='auto') # 'auto' balances classes\n# features_resampled, labels_resampled = smote.fit_resample(features, labels)\n\n# # Merge the resampled features and labels back into a dataframe\n# merged_train_data_resampled = pd.concat([features_resampled, labels_resampled], axis=1)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:57.411262Z","iopub.execute_input":"2023-08-30T06:15:57.412204Z","iopub.status.idle":"2023-08-30T06:15:57.421321Z","shell.execute_reply.started":"2023-08-30T06:15:57.412154Z","shell.execute_reply":"2023-08-30T06:15:57.419360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merged_sentiment_count = merged_train_data_resampled ['sentiment'].value_counts()\n# merged_sentiment_count\n\n# merged_sentiment_percent = merged_sentiment_count/len(merged_train_data_resampled ) * 100\n# merged_sentiment_percent","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:57.423824Z","iopub.execute_input":"2023-08-30T06:15:57.424818Z","iopub.status.idle":"2023-08-30T06:15:57.438554Z","shell.execute_reply.started":"2023-08-30T06:15:57.424770Z","shell.execute_reply":"2023-08-30T06:15:57.436794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1    50.0\n# 0    50.0\n# Name: sentiment, dtype: float64","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:57.441058Z","iopub.execute_input":"2023-08-30T06:15:57.441925Z","iopub.status.idle":"2023-08-30T06:15:57.451355Z","shell.execute_reply.started":"2023-08-30T06:15:57.441881Z","shell.execute_reply":"2023-08-30T06:15:57.450464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_percentage = 50.0\nnegative_percentage = 50.0\n\n# Data for the pie chart\nlabels = ['Positive', 'Negative']\nsizes = [positive_percentage, negative_percentage]\ncolors = ['skyblue', 'lightcoral']\n\n# Create the pie chart without explode and shadow\nplt.figure(figsize=(6, 6))\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nplt.title('Sentiment Distribution')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:57.453318Z","iopub.execute_input":"2023-08-30T06:15:57.454251Z","iopub.status.idle":"2023-08-30T06:15:57.635332Z","shell.execute_reply.started":"2023-08-30T06:15:57.454206Z","shell.execute_reply":"2023-08-30T06:15:57.633586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that our dataset is balanced now with 50% positive and 50% negative classes by applying **SMOTE**. However, on further analysis, it was found that balancing the dataset **did now bring any significant improvements to our model**, hence we will be proceeding forward with the imbalanced dataset and commenting out the above code for balancing the dataset.","metadata":{}},{"cell_type":"markdown","source":"#### Take-aways:\n\n1. Applying SMOTE balanced our dataset.\n\n2. However, it on further analysis there was **no significant improvement** to the models.\n\n3. Hence, we will drop the idea of balancing our dataset and **proceed with the imbalanced dataset.**","metadata":{}},{"cell_type":"markdown","source":"______________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"markdown","source":"### Intuitive EDA","metadata":{}},{"cell_type":"code","source":"sns.displot(data=merged_train_data, x='audienceScore', hue='sentiment', kind='kde')\n# Set the labels and title\n#plt.xlabel('Sentiment')\nplt.ylabel('Audience Score')\nplt.title('How Audience Score affects the sentiment ')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:57.637668Z","iopub.execute_input":"2023-08-30T06:15:57.638760Z","iopub.status.idle":"2023-08-30T06:15:59.173464Z","shell.execute_reply.started":"2023-08-30T06:15:57.638694Z","shell.execute_reply":"2023-08-30T06:15:59.172287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(data=merged_train_data, x='runtimeMinutes', hue='sentiment', kind='kde')\n# Set the labels and title\n#plt.label('Sentiment')\nplt.ylabel('Runtime Minutes')\nplt.title('How runtime Minutes affects the sentiment ')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:15:59.194300Z","iopub.execute_input":"2023-08-30T06:15:59.194735Z","iopub.status.idle":"2023-08-30T06:16:00.890149Z","shell.execute_reply.started":"2023-08-30T06:15:59.194703Z","shell.execute_reply":"2023-08-30T06:16:00.888976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary\n\n> The missing values were **Imputed** for the various columns.\n\n> **English** was the most frequently used languages,\n\n> Most movies were **Drama** based.\n\n> The **data imbalance** is conserved in the merged movies and train dataset.\n\n> There seems to be a correlation between **audienceScore** and **sentiment** as well as **runtimeMinutes** and **sentiment**","metadata":{}},{"cell_type":"markdown","source":"## Merging test and movies dataset","metadata":{}},{"cell_type":"code","source":"merged_test_data = pd.merge(test_copy, duplicate_movie, on='movieid', how='left')\nmerged_test_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:00.891616Z","iopub.execute_input":"2023-08-30T06:16:00.891982Z","iopub.status.idle":"2023-08-30T06:16:01.048749Z","shell.execute_reply.started":"2023-08-30T06:16:00.891948Z","shell.execute_reply":"2023-08-30T06:16:01.047233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_test_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.050826Z","iopub.execute_input":"2023-08-30T06:16:01.051661Z","iopub.status.idle":"2023-08-30T06:16:01.059443Z","shell.execute_reply.started":"2023-08-30T06:16:01.051622Z","shell.execute_reply":"2023-08-30T06:16:01.057662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_value_percent(merged_test_data)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.061009Z","iopub.execute_input":"2023-08-30T06:16:01.061361Z","iopub.status.idle":"2023-08-30T06:16:01.226209Z","shell.execute_reply.started":"2023-08-30T06:16:01.061331Z","shell.execute_reply":"2023-08-30T06:16:01.225056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the same imputations technique used in the merged_train_dataset to handle missing values in merged_train_dataset\n\nimpute_column_with_median(merged_test_data, 'audienceScore')\n\nimpute_column_with_most_frequent(merged_test_data, 'releaseDateStreaming')\n\nimpute_column_with_most_frequent(merged_test_data, 'genre')\n\nimpute_column_with_most_frequent(merged_test_data, 'originalLanguage')\n\nimpute_column_with_median(merged_test_data, 'runtimeMinutes')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.227763Z","iopub.execute_input":"2023-08-30T06:16:01.228815Z","iopub.status.idle":"2023-08-30T06:16:01.295748Z","shell.execute_reply.started":"2023-08-30T06:16:01.228777Z","shell.execute_reply":"2023-08-30T06:16:01.294456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_value_percent(merged_test_data)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.297351Z","iopub.execute_input":"2023-08-30T06:16:01.298452Z","iopub.status.idle":"2023-08-30T06:16:01.460156Z","shell.execute_reply.started":"2023-08-30T06:16:01.298407Z","shell.execute_reply":"2023-08-30T06:16:01.459336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> We have **removed all the missing values** from our **merged training and test dataset**. We can move forward to splitting the dataset for further treatment","metadata":{}},{"cell_type":"markdown","source":"## Scaling our data","metadata":{}},{"cell_type":"code","source":"# Use MinMax Scaler to scale the runtimeMinutes and audienceScore columns\n\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef min_max_scale(data, column):\n    \n    # Create the MinMaxScaler\n    min_max_scaler = MinMaxScaler()\n    \n    # Reshape the column into a 2D array\n    column_2d = data[column].values.reshape(-1, 1)\n    \n    # Apply Min-Max Scaling to the column in-place\n    data[column] = min_max_scaler.fit_transform(column_2d)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.461353Z","iopub.execute_input":"2023-08-30T06:16:01.462141Z","iopub.status.idle":"2023-08-30T06:16:01.467790Z","shell.execute_reply.started":"2023-08-30T06:16:01.462107Z","shell.execute_reply":"2023-08-30T06:16:01.466853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaling the columns of audienceScore, runtimeMinutes for both merged training and test data\nmin_max_scale(merged_train_data,'audienceScore')\nmin_max_scale(merged_train_data,'runtimeMinutes')\n\n\nmin_max_scale(merged_test_data,'audienceScore')\nmin_max_scale(merged_test_data,'runtimeMinutes')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.469533Z","iopub.execute_input":"2023-08-30T06:16:01.470024Z","iopub.status.idle":"2023-08-30T06:16:01.489838Z","shell.execute_reply.started":"2023-08-30T06:16:01.469982Z","shell.execute_reply":"2023-08-30T06:16:01.488521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting our dataset","metadata":{}},{"cell_type":"code","source":"# splitting the merged dataset into train and test set\n\nmerge_train, merge_test = train_test_split(merged_train_data, test_size = 0.2, stratify= merged_train_data.sentiment, random_state = 10)\nmerge_train.shape, merge_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.491542Z","iopub.execute_input":"2023-08-30T06:16:01.492036Z","iopub.status.idle":"2023-08-30T06:16:01.713818Z","shell.execute_reply.started":"2023-08-30T06:16:01.491980Z","shell.execute_reply":"2023-08-30T06:16:01.712469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_train = merge_train[merge_train.sentiment==1]\nnegative_train = merge_train[merge_train.sentiment==0]\n\n\npositive_test = merge_test[merge_test.sentiment==1]\nnegative_test = merge_test[merge_test.sentiment==0]\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.715715Z","iopub.execute_input":"2023-08-30T06:16:01.716392Z","iopub.status.idle":"2023-08-30T06:16:01.770197Z","shell.execute_reply.started":"2023-08-30T06:16:01.716342Z","shell.execute_reply":"2023-08-30T06:16:01.768899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check imbalance\n\n(positive_train.shape,negative_train.shape),(positive_test.shape,negative_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.771889Z","iopub.execute_input":"2023-08-30T06:16:01.773283Z","iopub.status.idle":"2023-08-30T06:16:01.781163Z","shell.execute_reply.started":"2023-08-30T06:16:01.773241Z","shell.execute_reply":"2023-08-30T06:16:01.779961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_train.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.783053Z","iopub.execute_input":"2023-08-30T06:16:01.783527Z","iopub.status.idle":"2023-08-30T06:16:01.833949Z","shell.execute_reply.started":"2023-08-30T06:16:01.783491Z","shell.execute_reply":"2023-08-30T06:16:01.832314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"negative_train.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.836405Z","iopub.execute_input":"2023-08-30T06:16:01.837745Z","iopub.status.idle":"2023-08-30T06:16:01.873702Z","shell.execute_reply.started":"2023-08-30T06:16:01.837692Z","shell.execute_reply":"2023-08-30T06:16:01.872209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_test.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.875532Z","iopub.execute_input":"2023-08-30T06:16:01.875943Z","iopub.status.idle":"2023-08-30T06:16:01.906986Z","shell.execute_reply.started":"2023-08-30T06:16:01.875909Z","shell.execute_reply":"2023-08-30T06:16:01.906046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"negative_test.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.908608Z","iopub.execute_input":"2023-08-30T06:16:01.909293Z","iopub.status.idle":"2023-08-30T06:16:01.941825Z","shell.execute_reply.started":"2023-08-30T06:16:01.909258Z","shell.execute_reply":"2023-08-30T06:16:01.940626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(merged_train_data.corr(numeric_only=True),annot=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:01.943769Z","iopub.execute_input":"2023-08-30T06:16:01.944696Z","iopub.status.idle":"2023-08-30T06:16:02.406790Z","shell.execute_reply.started":"2023-08-30T06:16:01.944649Z","shell.execute_reply":"2023-08-30T06:16:02.403504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **audienceScore** and **runtimeMinutes** seems to be correlated and is correlated to **sentiment** as well.","metadata":{}},{"cell_type":"code","source":"merged_train_data= merged_train_data.drop(columns = ['movieid','reviewerName','isFrequentReviewer','title','releaseDateStreaming','genre','originalLanguage','director'],axis=1)\nmerged_train_data","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:02.409013Z","iopub.execute_input":"2023-08-30T06:16:02.410052Z","iopub.status.idle":"2023-08-30T06:16:02.449493Z","shell.execute_reply.started":"2023-08-30T06:16:02.410008Z","shell.execute_reply":"2023-08-30T06:16:02.448537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"code","source":"X = merged_train_data[['reviewText', 'audienceScore', 'runtimeMinutes']]\ny = merged_train_data['sentiment']\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:02.451045Z","iopub.execute_input":"2023-08-30T06:16:02.451439Z","iopub.status.idle":"2023-08-30T06:16:02.470134Z","shell.execute_reply.started":"2023-08-30T06:16:02.451407Z","shell.execute_reply":"2023-08-30T06:16:02.468609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape,y.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:02.472068Z","iopub.execute_input":"2023-08-30T06:16:02.473605Z","iopub.status.idle":"2023-08-30T06:16:02.490563Z","shell.execute_reply.started":"2023-08-30T06:16:02.473516Z","shell.execute_reply":"2023-08-30T06:16:02.489058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing sets with stratified sampling\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=10)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:02.492070Z","iopub.execute_input":"2023-08-30T06:16:02.492566Z","iopub.status.idle":"2023-08-30T06:16:02.619247Z","shell.execute_reply.started":"2023-08-30T06:16:02.492531Z","shell.execute_reply":"2023-08-30T06:16:02.616522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:02.621024Z","iopub.execute_input":"2023-08-30T06:16:02.621679Z","iopub.status.idle":"2023-08-30T06:16:02.632785Z","shell.execute_reply.started":"2023-08-30T06:16:02.621644Z","shell.execute_reply":"2023-08-30T06:16:02.630060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation metrics functions","metadata":{}},{"cell_type":"markdown","source":"_________________________________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"code","source":"#Function to print the classification report as well as the F1-micro score and classification matrix\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\n\ndef report(X_test, y_test, pipeline):\n    # Check if the pipeline has a best_estimator_ attribute (for GridSearchCV)\n    if hasattr(pipeline, 'best_estimator_'):\n        best_estimator = pipeline.best_estimator_\n        y_pred = best_estimator.predict(X_test)\n    else:\n        y_pred = pipeline.predict(X_test)\n\n    # Print the classification report\n    report_text = classification_report(y_test, y_pred)\n    print(\"Classification Report:\\n\", report_text)\n    print(\"-------------------------------------------------------------\")\n\n    # Calculate and print the F1-micro score\n    f1_micro = f1_score(y_test, y_pred, average='micro')\n    print(\"F1-micro Score:\", f1_micro)\n    print(\"-------------------------------------------------------------\")\n\n    # Plot the confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', cbar=False)\n    plt.xlabel('Predicted Labels')\n    plt.ylabel('True Labels')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:02.634707Z","iopub.execute_input":"2023-08-30T06:16:02.635143Z","iopub.status.idle":"2023-08-30T06:16:02.648183Z","shell.execute_reply.started":"2023-08-30T06:16:02.635111Z","shell.execute_reply":"2023-08-30T06:16:02.645983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to plot the ROC curve and ROC AUC score\n\n\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\ndef plot_roc_curve(y_true, y_prob):\n    # Calculate ROC curve\n    fpr, tpr, _ = roc_curve(y_true, y_prob)\n\n    # Calculate ROC AUC score\n    roc_auc = roc_auc_score(y_true, y_prob)\n\n    # Plot ROC curve\n    plt.figure(figsize=(10, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc=\"lower right\")\n\n    # Plot ROC AUC curve\n    plt.figure(figsize=(6, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.fill_between(fpr, tpr, alpha=0.5, color='lightblue')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc=\"lower right\")\n\n    plt.show()\n\n    # Print ROC AUC score\n    print(f\"ROC AUC: {roc_auc:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:02.650125Z","iopub.execute_input":"2023-08-30T06:16:02.650703Z","iopub.status.idle":"2023-08-30T06:16:02.670288Z","shell.execute_reply.started":"2023-08-30T06:16:02.650630Z","shell.execute_reply":"2023-08-30T06:16:02.669020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_recall_curve, auc\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ndef plot_precision_recall_curve_for_pipeline(pipeline, classifier_step, X_train, y_train):\n    # Fit the pipeline on the training data\n    pipeline.fit(X_train, y_train)\n    \n    # Predict probabilities on the training data\n    if hasattr(pipeline.named_steps[classifier_step], 'predict_proba'):\n        y_scores = pipeline.predict_proba(X_train)[:, 1]\n    else:\n        y_scores = pipeline.decision_function(X_train)\n    \n    # Calculate precision-recall values\n    precision, recall, _ = precision_recall_curve(y_train, y_scores)\n    \n    # Calculate area under the curve (AUC)\n    pr_auc = auc(recall, precision)\n    \n    # Plot the precision-recall curve\n    plt.figure(figsize=(8, 6))\n    plt.plot(recall, precision, color='b', label='Precision-Recall curve (AUC = {:.2f})'.format(pr_auc))\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.legend(loc='lower left')\n    plt.grid(True)\n    plt.show()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:02.673248Z","iopub.execute_input":"2023-08-30T06:16:02.673776Z","iopub.status.idle":"2023-08-30T06:16:02.691816Z","shell.execute_reply.started":"2023-08-30T06:16:02.673733Z","shell.execute_reply":"2023-08-30T06:16:02.690745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Precision-Recall curve for Test set\n\ndef plot_precision_recall_curve_for_sets(pipeline, classifier_step, X_train, y_train, X_val, y_val):\n    # Fit the pipeline on the training data\n    pipeline.fit(X_train, y_train)\n    \n    # Plot for the training data\n    plot_precision_recall_curve(pipeline, classifier_step, X_train, y_train, title='Training Set')\n    \n    # Plot for the validation data\n    plot_precision_recall_curve(pipeline, classifier_step, X_val, y_val, title='Train Set')\n\ndef plot_precision_recall_curve(pipeline, classifier_step, X, y, title):\n    # Predict probabilities\n    if hasattr(pipeline.named_steps[classifier_step], 'predict_proba'):\n        y_scores = pipeline.predict_proba(X)[:, 1]\n    else:\n        y_scores = pipeline.decision_function(X)\n    \n    # Calculate precision-recall values\n    precision, recall, _ = precision_recall_curve(y, y_scores)\n    \n    # Calculate area under the curve (AUC)\n    pr_auc = auc(recall, precision)\n    \n    # Plot the precision-recall curve\n    plt.figure(figsize=(8, 6))\n    plt.plot(recall, precision, color='b', label='Precision-Recall curve (AUC = {:.2f})'.format(pr_auc))\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve - {}'.format(title))\n    plt.legend(loc='lower left')\n    plt.grid(True)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:02.693495Z","iopub.execute_input":"2023-08-30T06:16:02.693942Z","iopub.status.idle":"2023-08-30T06:16:02.711604Z","shell.execute_reply.started":"2023-08-30T06:16:02.693899Z","shell.execute_reply":"2023-08-30T06:16:02.710283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_________________________________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"markdown","source":"# Feature Extraction","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Define the tfidf_transformer\ntfidf_transformer = TfidfVectorizer()\n\n# Define the numeric_transformer\nnumeric_transformer = MinMaxScaler()\n\ntfidf_column = 'reviewText'  # No list here\nnumeric_columns = ['audienceScore', 'runtimeMinutes']\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('tfidf', tfidf_transformer, tfidf_column),  # No list here\n        ('numeric', numeric_transformer, numeric_columns)\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:02.713552Z","iopub.execute_input":"2023-08-30T06:16:02.714060Z","iopub.status.idle":"2023-08-30T06:16:02.759284Z","shell.execute_reply.started":"2023-08-30T06:16:02.714007Z","shell.execute_reply":"2023-08-30T06:16:02.757972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:02.762166Z","iopub.execute_input":"2023-08-30T06:16:02.764582Z","iopub.status.idle":"2023-08-30T06:16:02.770571Z","shell.execute_reply.started":"2023-08-30T06:16:02.764526Z","shell.execute_reply":"2023-08-30T06:16:02.769210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the pipeline with preprocessor and Linear Regression\npipe_log = Pipeline([\n    ('preprocessor', preprocessor),\n    ('logit', LogisticRegression(max_iter=1000))\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:02.772432Z","iopub.execute_input":"2023-08-30T06:16:02.773594Z","iopub.status.idle":"2023-08-30T06:16:02.788123Z","shell.execute_reply.started":"2023-08-30T06:16:02.773542Z","shell.execute_reply":"2023-08-30T06:16:02.786516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the pipeline on the training data\npipe_log.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:02.790264Z","iopub.execute_input":"2023-08-30T06:16:02.791691Z","iopub.status.idle":"2023-08-30T06:16:26.392007Z","shell.execute_reply.started":"2023-08-30T06:16:02.791649Z","shell.execute_reply":"2023-08-30T06:16:26.390392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test data\ny_pred_test = pipe_log.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:26.393817Z","iopub.execute_input":"2023-08-30T06:16:26.394319Z","iopub.status.idle":"2023-08-30T06:16:27.148205Z","shell.execute_reply.started":"2023-08-30T06:16:26.394275Z","shell.execute_reply":"2023-08-30T06:16:27.146821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_train = pipe_log.predict(X_train)\n\nreport(X_train,y_train,pipe_log)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:27.149550Z","iopub.execute_input":"2023-08-30T06:16:27.149920Z","iopub.status.idle":"2023-08-30T06:16:33.371414Z","shell.execute_reply.started":"2023-08-30T06:16:27.149889Z","shell.execute_reply":"2023-08-30T06:16:33.370049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test data\nreport(X_test, y_test, pipe_log)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:33.373213Z","iopub.execute_input":"2023-08-30T06:16:33.373612Z","iopub.status.idle":"2023-08-30T06:16:34.417003Z","shell.execute_reply.started":"2023-08-30T06:16:33.373581Z","shell.execute_reply":"2023-08-30T06:16:34.415674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_precision_recall_curve_for_sets(pipe_log, 'logit', X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:16:34.418953Z","iopub.execute_input":"2023-08-30T06:16:34.419333Z","iopub.status.idle":"2023-08-30T06:17:00.769500Z","shell.execute_reply.started":"2023-08-30T06:16:34.419301Z","shell.execute_reply":"2023-08-30T06:17:00.768481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NaiveBayes","metadata":{}},{"cell_type":"markdown","source":"> ### Multinomial Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n# Create a pipeline for Naive Bayes classifier\npipe_nb = Pipeline([\n    ('preprocessor', preprocessor),\n    ('nb', MultinomialNB())\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:00.770904Z","iopub.execute_input":"2023-08-30T06:17:00.771766Z","iopub.status.idle":"2023-08-30T06:17:00.787548Z","shell.execute_reply.started":"2023-08-30T06:17:00.771725Z","shell.execute_reply":"2023-08-30T06:17:00.785851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the pipeline on the training data\npipe_nb.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:00.789293Z","iopub.execute_input":"2023-08-30T06:17:00.789717Z","iopub.status.idle":"2023-08-30T06:17:04.080742Z","shell.execute_reply.started":"2023-08-30T06:17:00.789684Z","shell.execute_reply":"2023-08-30T06:17:04.079453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the labels on the test data\ny_pred = pipe_nb.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:04.082368Z","iopub.execute_input":"2023-08-30T06:17:04.082994Z","iopub.status.idle":"2023-08-30T06:17:04.823853Z","shell.execute_reply.started":"2023-08-30T06:17:04.082946Z","shell.execute_reply":"2023-08-30T06:17:04.822485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(X_train,y_train,pipe_nb)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:04.825595Z","iopub.execute_input":"2023-08-30T06:17:04.825960Z","iopub.status.idle":"2023-08-30T06:17:08.161258Z","shell.execute_reply.started":"2023-08-30T06:17:04.825930Z","shell.execute_reply":"2023-08-30T06:17:08.159870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(X_test, y_test, pipe_nb)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:08.162894Z","iopub.execute_input":"2023-08-30T06:17:08.163246Z","iopub.status.idle":"2023-08-30T06:17:09.152754Z","shell.execute_reply.started":"2023-08-30T06:17:08.163216Z","shell.execute_reply":"2023-08-30T06:17:09.151437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_prob = pipe_nb.predict_proba(X_test)[:, 1]\nplot_roc_curve(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:09.154789Z","iopub.execute_input":"2023-08-30T06:17:09.155473Z","iopub.status.idle":"2023-08-30T06:17:10.541990Z","shell.execute_reply.started":"2023-08-30T06:17:09.155395Z","shell.execute_reply":"2023-08-30T06:17:10.540803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_precision_recall_curve_for_sets(pipe_nb, 'nb', X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:10.543273Z","iopub.execute_input":"2023-08-30T06:17:10.543624Z","iopub.status.idle":"2023-08-30T06:17:18.048495Z","shell.execute_reply.started":"2023-08-30T06:17:10.543595Z","shell.execute_reply":"2023-08-30T06:17:18.047552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### Complement NB","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import ComplementNB\n# Create a pipeline for Naive Bayes classifier\npipe_cnb = Pipeline([\n    ('preprocessor', preprocessor),\n    ('nb', ComplementNB())\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:18.050093Z","iopub.execute_input":"2023-08-30T06:17:18.050746Z","iopub.status.idle":"2023-08-30T06:17:18.057569Z","shell.execute_reply.started":"2023-08-30T06:17:18.050713Z","shell.execute_reply":"2023-08-30T06:17:18.056089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the pipeline on the training data\npipe_cnb.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:18.059352Z","iopub.execute_input":"2023-08-30T06:17:18.059792Z","iopub.status.idle":"2023-08-30T06:17:21.302661Z","shell.execute_reply.started":"2023-08-30T06:17:18.059759Z","shell.execute_reply":"2023-08-30T06:17:21.300807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the labels on the test data\ny_pred = pipe_cnb.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:21.304873Z","iopub.execute_input":"2023-08-30T06:17:21.305447Z","iopub.status.idle":"2023-08-30T06:17:22.015019Z","shell.execute_reply.started":"2023-08-30T06:17:21.305370Z","shell.execute_reply":"2023-08-30T06:17:22.013856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(X_train,y_train,pipe_cnb)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:22.016688Z","iopub.execute_input":"2023-08-30T06:17:22.017049Z","iopub.status.idle":"2023-08-30T06:17:25.274613Z","shell.execute_reply.started":"2023-08-30T06:17:22.017019Z","shell.execute_reply":"2023-08-30T06:17:25.273466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(X_test, y_test, pipe_cnb)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:25.276225Z","iopub.execute_input":"2023-08-30T06:17:25.277105Z","iopub.status.idle":"2023-08-30T06:17:26.252143Z","shell.execute_reply.started":"2023-08-30T06:17:25.277060Z","shell.execute_reply":"2023-08-30T06:17:26.250688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_precision_recall_curve_for_sets(pipe_cnb, 'nb', X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:26.253634Z","iopub.execute_input":"2023-08-30T06:17:26.253990Z","iopub.status.idle":"2023-08-30T06:17:33.705242Z","shell.execute_reply.started":"2023-08-30T06:17:26.253960Z","shell.execute_reply":"2023-08-30T06:17:33.703883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_prob = pipe_cnb.predict_proba(X_test)[:, 1]\nplot_roc_curve(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:33.707345Z","iopub.execute_input":"2023-08-30T06:17:33.707745Z","iopub.status.idle":"2023-08-30T06:17:35.046600Z","shell.execute_reply.started":"2023-08-30T06:17:33.707710Z","shell.execute_reply":"2023-08-30T06:17:35.045448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SGD Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\n\npipe_sgd = Pipeline([\n    ('preprocessor', preprocessor),\n    ('sgd', SGDClassifier(random_state=5))\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:35.047925Z","iopub.execute_input":"2023-08-30T06:17:35.048262Z","iopub.status.idle":"2023-08-30T06:17:35.054852Z","shell.execute_reply.started":"2023-08-30T06:17:35.048234Z","shell.execute_reply":"2023-08-30T06:17:35.053332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the pipeline on the training data\npipe_sgd.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:35.056501Z","iopub.execute_input":"2023-08-30T06:17:35.056974Z","iopub.status.idle":"2023-08-30T06:17:38.711466Z","shell.execute_reply.started":"2023-08-30T06:17:35.056931Z","shell.execute_reply":"2023-08-30T06:17:38.710293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the labels on the test data\ny_pred = pipe_sgd.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:38.713232Z","iopub.execute_input":"2023-08-30T06:17:38.713725Z","iopub.status.idle":"2023-08-30T06:17:39.391971Z","shell.execute_reply.started":"2023-08-30T06:17:38.713685Z","shell.execute_reply":"2023-08-30T06:17:39.390808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(X_train,y_train,pipe_sgd)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:39.393552Z","iopub.execute_input":"2023-08-30T06:17:39.393899Z","iopub.status.idle":"2023-08-30T06:17:42.527953Z","shell.execute_reply.started":"2023-08-30T06:17:39.393869Z","shell.execute_reply":"2023-08-30T06:17:42.526728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(X_test, y_test, pipe_sgd)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:42.529296Z","iopub.execute_input":"2023-08-30T06:17:42.529689Z","iopub.status.idle":"2023-08-30T06:17:43.498100Z","shell.execute_reply.started":"2023-08-30T06:17:42.529657Z","shell.execute_reply":"2023-08-30T06:17:43.496805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_precision_recall_curve_for_sets(pipe_sgd, 'sgd', X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:43.499629Z","iopub.execute_input":"2023-08-30T06:17:43.500146Z","iopub.status.idle":"2023-08-30T06:17:51.167203Z","shell.execute_reply.started":"2023-08-30T06:17:43.500106Z","shell.execute_reply":"2023-08-30T06:17:51.166279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred_prob = pipe_sgd.predict_proba(X_test)[:, 1]\nplot_roc_curve(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:51.168488Z","iopub.execute_input":"2023-08-30T06:17:51.169257Z","iopub.status.idle":"2023-08-30T06:17:51.929628Z","shell.execute_reply.started":"2023-08-30T06:17:51.169218Z","shell.execute_reply":"2023-08-30T06:17:51.928446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Light Gradient Boosting Model Classifier ","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\npipe_lgbm = Pipeline([\n    ('preprocessor', preprocessor),  # TF-IDF vectorizer\n    ('lgbm', LGBMClassifier(random_state=5))  # LightGBM classifier\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:51.931199Z","iopub.execute_input":"2023-08-30T06:17:51.931611Z","iopub.status.idle":"2023-08-30T06:17:53.098986Z","shell.execute_reply.started":"2023-08-30T06:17:51.931576Z","shell.execute_reply":"2023-08-30T06:17:53.097764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe_lgbm.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:17:53.100477Z","iopub.execute_input":"2023-08-30T06:17:53.101432Z","iopub.status.idle":"2023-08-30T06:18:27.628645Z","shell.execute_reply.started":"2023-08-30T06:17:53.101359Z","shell.execute_reply":"2023-08-30T06:18:27.627264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = pipe_lgbm.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:18:27.630725Z","iopub.execute_input":"2023-08-30T06:18:27.631229Z","iopub.status.idle":"2023-08-30T06:18:28.485232Z","shell.execute_reply.started":"2023-08-30T06:18:27.631184Z","shell.execute_reply":"2023-08-30T06:18:28.483963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(X_train,y_train,pipe_lgbm)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:18:28.486579Z","iopub.execute_input":"2023-08-30T06:18:28.487657Z","iopub.status.idle":"2023-08-30T06:18:32.373656Z","shell.execute_reply.started":"2023-08-30T06:18:28.487618Z","shell.execute_reply":"2023-08-30T06:18:32.372510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(X_test, y_test, pipe_lgbm)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:18:32.375073Z","iopub.execute_input":"2023-08-30T06:18:32.375487Z","iopub.status.idle":"2023-08-30T06:18:33.544425Z","shell.execute_reply.started":"2023-08-30T06:18:32.375448Z","shell.execute_reply":"2023-08-30T06:18:33.542839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_precision_recall_curve_for_sets(pipe_lgbm, 'lgbm', X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:18:33.545992Z","iopub.execute_input":"2023-08-30T06:18:33.546348Z","iopub.status.idle":"2023-08-30T06:19:14.280058Z","shell.execute_reply.started":"2023-08-30T06:18:33.546319Z","shell.execute_reply":"2023-08-30T06:19:14.278340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate predicted probabilities for ROC curve\ny_prob_test = pipe_lgbm.predict_proba(X_test)[:, 1]\n\n# Plot ROC curve and calculate ROC AUC score\nplot_roc_curve(y_test, y_prob_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:19:14.281595Z","iopub.execute_input":"2023-08-30T06:19:14.281969Z","iopub.status.idle":"2023-08-30T06:19:15.779861Z","shell.execute_reply.started":"2023-08-30T06:19:14.281937Z","shell.execute_reply":"2023-08-30T06:19:15.778399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Linear SVC","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\npipe_svc = Pipeline([\n    ('preprocessor', preprocessor),  # TF-IDF vectorizer\n    ('svc', LinearSVC(random_state=5,max_iter=2000))  # LinearSVC classifier\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:19:15.781490Z","iopub.execute_input":"2023-08-30T06:19:15.781923Z","iopub.status.idle":"2023-08-30T06:19:15.788868Z","shell.execute_reply.started":"2023-08-30T06:19:15.781882Z","shell.execute_reply":"2023-08-30T06:19:15.787733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe_svc.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:19:15.790305Z","iopub.execute_input":"2023-08-30T06:19:15.790737Z","iopub.status.idle":"2023-08-30T06:19:21.699861Z","shell.execute_reply.started":"2023-08-30T06:19:15.790706Z","shell.execute_reply":"2023-08-30T06:19:21.698667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = pipe_svc.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:19:21.701108Z","iopub.execute_input":"2023-08-30T06:19:21.701472Z","iopub.status.idle":"2023-08-30T06:19:22.386557Z","shell.execute_reply.started":"2023-08-30T06:19:21.701442Z","shell.execute_reply":"2023-08-30T06:19:22.385256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(X_train,y_train,pipe_svc)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:19:22.388161Z","iopub.execute_input":"2023-08-30T06:19:22.388691Z","iopub.status.idle":"2023-08-30T06:19:25.607993Z","shell.execute_reply.started":"2023-08-30T06:19:22.388647Z","shell.execute_reply":"2023-08-30T06:19:25.606832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(X_test, y_test, pipe_svc)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:19:25.609487Z","iopub.execute_input":"2023-08-30T06:19:25.610546Z","iopub.status.idle":"2023-08-30T06:19:26.543354Z","shell.execute_reply.started":"2023-08-30T06:19:25.610503Z","shell.execute_reply":"2023-08-30T06:19:26.542104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the precision_recall curve\nplot_precision_recall_curve_for_sets(pipe_svc, 'svc', X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:19:26.545261Z","iopub.execute_input":"2023-08-30T06:19:26.546037Z","iopub.status.idle":"2023-08-30T06:19:36.308824Z","shell.execute_reply.started":"2023-08-30T06:19:26.545991Z","shell.execute_reply":"2023-08-30T06:19:36.307650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calibrated SVC","metadata":{}},{"cell_type":"code","source":"from sklearn.calibration import CalibratedClassifierCV\n\n# Create a calibrated classifier from the LinearSVC\ncalibrated_svc = CalibratedClassifierCV(pipe_svc)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:19:36.310607Z","iopub.execute_input":"2023-08-30T06:19:36.311320Z","iopub.status.idle":"2023-08-30T06:19:36.332778Z","shell.execute_reply.started":"2023-08-30T06:19:36.311279Z","shell.execute_reply":"2023-08-30T06:19:36.331776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"calibrated_svc.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:19:36.334143Z","iopub.execute_input":"2023-08-30T06:19:36.335507Z","iopub.status.idle":"2023-08-30T06:20:02.738404Z","shell.execute_reply.started":"2023-08-30T06:19:36.335461Z","shell.execute_reply":"2023-08-30T06:20:02.737420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate predicted probabilities for ROC curve\ny_prob_test = calibrated_svc.predict_proba(X_test)[:, 1]\n\n# Plot ROC curve and calculate ROC AUC score\nplot_roc_curve(y_test, y_prob_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:20:02.739612Z","iopub.execute_input":"2023-08-30T06:20:02.740428Z","iopub.status.idle":"2023-08-30T06:20:06.831456Z","shell.execute_reply.started":"2023-08-30T06:20:02.740391Z","shell.execute_reply":"2023-08-30T06:20:06.830203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(X_train,y_train,calibrated_svc)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:20:06.832976Z","iopub.execute_input":"2023-08-30T06:20:06.833332Z","iopub.status.idle":"2023-08-30T06:20:21.245623Z","shell.execute_reply.started":"2023-08-30T06:20:06.833302Z","shell.execute_reply":"2023-08-30T06:20:21.244408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the evaluation report\nreport(X_test, y_test, calibrated_svc)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:20:21.247439Z","iopub.execute_input":"2023-08-30T06:20:21.248178Z","iopub.status.idle":"2023-08-30T06:20:24.971750Z","shell.execute_reply.started":"2023-08-30T06:20:21.248133Z","shell.execute_reply":"2023-08-30T06:20:24.970775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# Create a pipeline for XGBoost sentiment analysis\npipe_xgboost = Pipeline([\n    ('preprocessor', preprocessor),  \n    ('xgboost', XGBClassifier(random_state=42))  # XGBoost classifier\n    ])\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:20:24.973086Z","iopub.execute_input":"2023-08-30T06:20:24.973825Z","iopub.status.idle":"2023-08-30T06:20:25.192068Z","shell.execute_reply.started":"2023-08-30T06:20:24.973765Z","shell.execute_reply":"2023-08-30T06:20:25.190951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the pipeline on the training data\npipe_xgboost.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:20:25.193567Z","iopub.execute_input":"2023-08-30T06:20:25.194169Z","iopub.status.idle":"2023-08-30T06:21:35.102879Z","shell.execute_reply.started":"2023-08-30T06:20:25.194132Z","shell.execute_reply":"2023-08-30T06:21:35.101408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on the test data\ny_pred = pipe_xgboost.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:21:35.105321Z","iopub.execute_input":"2023-08-30T06:21:35.105849Z","iopub.status.idle":"2023-08-30T06:21:35.932186Z","shell.execute_reply.started":"2023-08-30T06:21:35.105806Z","shell.execute_reply":"2023-08-30T06:21:35.931100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(X_train,y_train,pipe_xgboost)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:21:35.933889Z","iopub.execute_input":"2023-08-30T06:21:35.934365Z","iopub.status.idle":"2023-08-30T06:21:39.669447Z","shell.execute_reply.started":"2023-08-30T06:21:35.934326Z","shell.execute_reply":"2023-08-30T06:21:39.668216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(X_test, y_test, pipe_xgboost)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:21:39.670788Z","iopub.execute_input":"2023-08-30T06:21:39.671120Z","iopub.status.idle":"2023-08-30T06:21:40.770764Z","shell.execute_reply.started":"2023-08-30T06:21:39.671091Z","shell.execute_reply":"2023-08-30T06:21:40.769637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the precision_recall curve\nplot_precision_recall_curve_for_sets(pipe_xgboost, 'xgboost', X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:21:40.772158Z","iopub.execute_input":"2023-08-30T06:21:40.772525Z","iopub.status.idle":"2023-08-30T06:22:54.522908Z","shell.execute_reply.started":"2023-08-30T06:21:40.772495Z","shell.execute_reply":"2023-08-30T06:22:54.521653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparative Analysis of models","metadata":{}},{"cell_type":"markdown","source":"## Precision-Recall curve comparision","metadata":{}},{"cell_type":"code","source":"# List of pipelines\npipelines = [\n    (pipe_log, 'logit'),\n    (pipe_nb, 'nb'),\n    (pipe_sgd, 'sgd'),\n    (pipe_lgbm, 'lgbm'),\n    (pipe_svc, 'svc'),\n    (pipe_xgboost, 'xgboost')\n]","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:43:37.349572Z","iopub.execute_input":"2023-08-30T06:43:37.350016Z","iopub.status.idle":"2023-08-30T06:43:37.356193Z","shell.execute_reply.started":"2023-08-30T06:43:37.349985Z","shell.execute_reply":"2023-08-30T06:43:37.355092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Aggregrate PR curves on Training set\n\ndef agg_precision_recall_curve_train(pipelines, X_train, y_train, title):\n    plt.figure(figsize=(10, 6))\n  \n    for pipeline, classifier_step in pipelines:\n        # Fit the pipeline on the training data\n        pipeline.fit(X_train, y_train)\n        \n        # Predict probabilities or decision function\n        if hasattr(pipeline.named_steps[classifier_step], 'predict_proba'):\n            y_scores = pipeline.predict_proba(X_train)[:, 1]\n        else:\n            y_scores = pipeline.decision_function(X_train)\n        \n        # Calculate precision-recall values\n        precision, recall, _ = precision_recall_curve(y_train, y_scores)\n        \n        # Calculate area under the curve (AUC)\n        pr_auc = auc(recall, precision)\n        \n        # Plot the precision-recall curve\n        plt.plot(recall, precision, label='{} (AUC = {:.2f})'.format(classifier_step, pr_auc))\n\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title(title)\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n    \nagg_precision_recall_curve_train(pipelines, X_train, y_train, 'Precision-Recall Curves (Training Data)')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:38:48.455634Z","iopub.execute_input":"2023-08-30T06:38:48.456221Z","iopub.status.idle":"2023-08-30T06:41:27.798706Z","shell.execute_reply.started":"2023-08-30T06:38:48.456178Z","shell.execute_reply":"2023-08-30T06:41:27.797544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Aggregrate PR curves on Test set\n\ndef agg_precision_recall_curve_test(pipelines, X_test, y_test, title):\n    plt.figure(figsize=(10, 6))\n  \n    for pipeline, classifier_step in pipelines:\n        # Predict probabilities or decision function\n        if hasattr(pipeline.named_steps[classifier_step], 'predict_proba'):\n            y_scores = pipeline.predict_proba(X_test)[:, 1]\n        else:\n            y_scores = pipeline.decision_function(X_test)\n        \n        # Calculate precision-recall values\n        precision, recall, _ = precision_recall_curve(y_test, y_scores)\n        \n        # Calculate area under the curve (AUC)\n        pr_auc = auc(recall, precision)\n        \n        # Plot the precision-recall curve\n        plt.plot(recall, precision, label='{} (AUC = {:.2f})'.format(classifier_step, pr_auc))\n\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title(title)\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n    \nagg_precision_recall_curve_test(pipelines, X_test, y_test, 'Precision-Recall Curves (Test Data)')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:41:27.800636Z","iopub.execute_input":"2023-08-30T06:41:27.801703Z","iopub.status.idle":"2023-08-30T06:41:32.877450Z","shell.execute_reply.started":"2023-08-30T06:41:27.801667Z","shell.execute_reply":"2023-08-30T06:41:32.876261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## F1-micro score comparision","metadata":{}},{"cell_type":"code","source":"# Initialize lists to store F1-micro scores\nf1_micro_train = []\nf1_micro_test = []\nlabels = []\n\n# Define a function to calculate and plot F1-micro scores\ndef calculate_f1_micro(pipeline, classifier_step, X_train, y_train, X_test, y_test, label_prefix):\n    # Fit the pipeline on the training data\n    pipeline.fit(X_train, y_train)\n    \n    # Predict on the training and test data\n    y_pred_train = pipeline.predict(X_train)\n    y_pred_test = pipeline.predict(X_test)\n    \n    # Calculate F1-micro scores\n    f1_train = f1_score(y_train, y_pred_train, average='micro')\n    f1_test = f1_score(y_test, y_pred_test, average='micro')\n    \n    # Append to lists\n    f1_micro_train.append(f1_train)\n    f1_micro_test.append(f1_test)\n    labels.append(label_prefix)\n\n# Iterate through the pipelines to calculate F1-micro scores\nfor pipeline, classifier_step in pipelines:\n    calculate_f1_micro(pipeline, classifier_step, X_train, y_train, X_test, y_test, classifier_step)\n\n# Plot the bar graph\nplt.figure(figsize=(10, 6))\nx = range(len(labels))\nplt.bar(x, f1_micro_train, width=0.4, align='center', label='Training')\nplt.bar(x, f1_micro_test, width=0.4, align='edge', label='Test')\nplt.xticks(x, labels)\nplt.xlabel('Model')\nplt.ylabel('F1-micro Score')\nplt.title('F1-micro Scores (Train vs Test)')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:28:18.969238Z","iopub.execute_input":"2023-08-30T06:28:18.969634Z","iopub.status.idle":"2023-08-30T06:31:01.138018Z","shell.execute_reply.started":"2023-08-30T06:28:18.969599Z","shell.execute_reply":"2023-08-30T06:31:01.136772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\n# Lists to store the F1-micro scores\nf1_scores_train = []\nf1_scores_test = []\n\n# Calculate F1-micro scores for each pipeline\nfor pipeline, classifier_step in pipelines:\n    pipeline_name = classifier_step  # You can customize this name\n\n    # For the training set\n    y_pred_train = pipeline.predict(X_train)\n    f1_train = f1_score(y_train, y_pred_train, average='micro')\n    f1_scores_train.append((pipeline_name, f1_train))\n\n    # For the test set\n    y_pred_test = pipeline.predict(X_test)\n    f1_test = f1_score(y_test, y_pred_test, average='micro')\n    f1_scores_test.append((pipeline_name, f1_test))\n\n# Sort the F1-micro scores in descending order\nf1_scores_train_sorted = sorted(f1_scores_train, key=lambda x: x[1], reverse=True)\nf1_scores_test_sorted = sorted(f1_scores_test, key=lambda x: x[1], reverse=True)\n\n# Function to print and plot the F1-micro scores\ndef display_and_plot(scores, title):\n    print(title)\n    for model, score in scores:\n        print(f\"Model: {model}, F1-micro Score: {score:.2f}\")\n\n    # Plot the bar graph\n    models, values = zip(*scores)\n    plt.bar(models, values)\n    plt.xlabel('Model')\n    plt.ylabel('F1-micro Score')\n    plt.title(title)\n    plt.xticks(rotation=45)\n    plt.show()\n\n# Display and plot for both training and test sets\ndisplay_and_plot(f1_scores_train_sorted, 'F1-micro Scores on Training Set (X_train, y_train) in Descending Order')\ndisplay_and_plot(f1_scores_test_sorted, 'F1-micro Scores on Test Set (X_test, y_test) in Descending Order')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:31:01.139716Z","iopub.execute_input":"2023-08-30T06:31:01.140079Z","iopub.status.idle":"2023-08-30T06:31:24.144742Z","shell.execute_reply.started":"2023-08-30T06:31:01.140048Z","shell.execute_reply":"2023-08-30T06:31:24.143385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparision of the losses - brier_score_loss","metadata":{}},{"cell_type":"code","source":"\n\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.metrics import brier_score_loss\n\n# Lists to store names and losses\nnames = []\nlosses = []\n\n# Iterate through the pipelines and compute the loss\nfor pipeline, name in pipelines:\n    try:\n        # Make predictions on the test data\n        y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n    except AttributeError:\n        # Calibrate the model to provide probabilities, using the updated parameter name\n        calibrated_clf = CalibratedClassifierCV(estimator=pipeline, method='sigmoid')\n        calibrated_clf.fit(X_train, y_train)\n        y_pred_proba = calibrated_clf.predict_proba(X_test)[:, 1]\n\n    # Compute the Brier Score Loss\n    loss = brier_score_loss(y_test, y_pred_proba)\n\n    print(f\"Brier Score Loss for {name}: {loss}\")\n\n    # Append to lists\n    names.append(name)\n    losses.append(loss)\n\n# Create a DataFrame and sort by Brier Score Loss\nimport pandas as pd\n\nresults_df = pd.DataFrame({\n    'Model': names,\n    'Brier Score Loss': losses\n})\nresults_df = results_df.sort_values(by='Brier Score Loss', ascending=True)\n\ncolors = ['red', 'green', 'blue', 'orange', 'purple', 'brown']\n\nplt.bar(results_df['Model'], results_df['Brier Score Loss'], color=colors)\nplt.ylabel('Brier Score Loss')\nplt.title('Brier Score Loss for Different Models')\nplt.xticks(rotation=45)\nplt.show()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:31:24.146253Z","iopub.execute_input":"2023-08-30T06:31:24.146688Z","iopub.status.idle":"2023-08-30T06:32:18.943680Z","shell.execute_reply.started":"2023-08-30T06:31:24.146655Z","shell.execute_reply":"2023-08-30T06:32:18.942353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Take-away of the loss analysis:\n\n> *logit* and *svc* have the lowest losses, meaning they perform better compared to the other models.","metadata":{}},{"cell_type":"markdown","source":"#### To identify models with the Highest and lowest TP,FP,TN,FN ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Initialize variables to track highest and lowest TP, FP, FN, FP values\nlowest_tp = lowest_fp = lowest_fn = lowest_tn = float('inf')\nhighest_tp = highest_fp = highest_fn = highest_tn = float('-inf')\n\n# Lists to store results\nhighest_values = []\nlowest_values = []\nmetrics = ['TP', 'FP', 'FN', 'TN']\nmodels_highest = []\nmodels_lowest = []\n\n# Iterate through the pipelines\nfor pipeline, classifier_step in pipelines:\n    pipeline_name = classifier_step \n    y_pred = pipeline.predict(X_test)\n\n    cm = confusion_matrix(y_test, y_pred)\n    tp, fp, fn, tn = cm.ravel()\n\n    # Check for highest values\n    if tp > highest_tp:\n        highest_tp = tp\n        highest_tp_model = pipeline_name\n    if fp > highest_fp:\n        highest_fp = fp\n        highest_fp_model = pipeline_name\n    if fn > highest_fn:\n        highest_fn = fn\n        highest_fn_model = pipeline_name\n    if tn > highest_tn:\n        highest_tn = tn\n        highest_tn_model = pipeline_name\n\n    # Check for lowest values\n    if tp < lowest_tp:\n        lowest_tp = tp\n        lowest_tp_model = pipeline_name\n    if fp < lowest_fp:\n        lowest_fp = fp\n        lowest_fp_model = pipeline_name\n    if fn < lowest_fn:\n        lowest_fn = fn\n        lowest_fn_model = pipeline_name\n    if tn < lowest_tn:\n        lowest_tn = tn\n        lowest_tn_model = pipeline_name\n\n    print(f\"Pipeline: {pipeline_name}\")\n    print(f\"True Positives: {tp}, False Positives: {fp}, False Negatives: {fn}, True Negatives: {tn}\")\n    print(\"-------------------------------------------------------------\")\n\n# Store the highest and lowest values\nhighest_values = [highest_tp, highest_fp, highest_fn, highest_tn]\nlowest_values = [lowest_tp, lowest_fp, lowest_fn, lowest_tn]\nmodels_highest = [highest_tp_model, highest_fp_model, highest_fn_model, highest_tn_model]\nmodels_lowest = [lowest_tp_model, lowest_fp_model, lowest_fn_model, lowest_tn_model]\n\n# Function to plot the bar graph\ndef plot_bar_graph(values, models, title):\n    plt.bar(metrics, values)\n    for i, value in enumerate(values):\n        plt.text(i, value / 2, models[i], ha='center', color='black')  # Color changed to black\n    plt.xlabel('Metric')\n    plt.ylabel('Value')\n    plt.title(title)\n    plt.show()\n\n# Plot the graphs\nplot_bar_graph(highest_values, models_highest, 'Models with Highest Values')\nplot_bar_graph(lowest_values, models_lowest, 'Models with Lowest Values')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:18.946002Z","iopub.execute_input":"2023-08-30T06:32:18.946516Z","iopub.status.idle":"2023-08-30T06:32:23.840869Z","shell.execute_reply.started":"2023-08-30T06:32:18.946472Z","shell.execute_reply":"2023-08-30T06:32:23.839516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary(without Hyper-parameter Tuning)\n\n## Model summary without hyper-parameter tuning\n \n> In terms of accuracy,the top performing models without hyper-parameter tuning are: **LogisticRegressor,Calibrated LinearSVC with 80%, Complement Naive Bayes** with an accuracy of **79%**\n\n## Model Analysis\n### Logistic Regression (logit):\n\n> **Pros**: Balanced detection of both positive and negative sentiments.\n\n> **Cons:** Potential misclassification may lead to inaccuracies in understanding customer sentiment, affecting decision-making in marketing or product development.\n\n> **Business Implication:** Ideal for a general overview of customer sentiment. Suitable for applications like brand monitoring where both positive and negative sentiments are equally important.\n\n\n### Naive Bayes (nb):\n\n> **Pros**: High detection of negative sentiments (low False Negatives).\n\n> **Cons:** The tendency to miss positive sentiments may lead to underestimation of customer satisfaction, potentially affecting strategies for brand promotion and loyalty programs.\n\n> **Business Implication:** Useful when it's crucial to capture negative feedback, such as in quality control or customer service improvement.\n\n### Stochastic Gradient Descent (sgd):\n\n> **Pros:** Balanced detection of positive and negative sentiments.\n\n> **Cons:** Moderate incorrect classifications could create challenges in precisely targeting customer segments or tailoring personalized marketing strategies.\n\n> **Business Implication:** A versatile option that might require further tuning for specific use cases like targeted marketing or product enhancement.\n\n### LightGBM (lgbm):\n\n> **Pros:** Reasonable detection of positive sentiments.\n\n> **Cons:** The potential misclassification of both positive and negative sentiments might lead to misguided business strategies, such as incorrect product improvements or inefficient allocation of resources.\n\n> **Business Implication:** May need tuning for applications like assessing customer satisfaction or promoting positive reviews.\n\n### Support Vector Classifier (svc):\n\n> **Pros:** Highest detection of positive sentiments.\n\n> **Cons:** Overlooking negative feedback might lead to missed opportunities for addressing customer grievances, potentially harming brand reputation or customer retention.\n\n> **Business Implication:** Suitable for highlighting and leveraging positive feedback, such as in advertising or enhancing positive brand image.\n\n### XGBoost (xgboost):\n\n> **Pros:** Balanced detection of positive and negative sentiments.\n\n> **Cons:** Some misclassifications may reduce the effectiveness of competitive analysis or market segmentation, leading to suboptimal business decisions.\n\n> **Business Implication:** A flexible option that might need more tuning for applications like market segmentation or competitive analysis.\n\n\n#### Decision:\n\n**Best Model:** Both logit and svc are strong candidates.\n\n> If the goal is to obtain a **balanced view of customer sentiments**, <code style=\"background:red;color:white\">logit</code> might be the preferred choice.\n\n> If the focus is on **leveraging positive feedback for marketing or brand enhancement**, <code style=\"background:red;color:white\">svc</code> might be more suitable.\n\n####  Business Considerations:\n    The choice of model should align with the specific goals of the sentiment analysis:\n\n- **Customer Service Improvement:** Focus on models that detect negative sentiments effectively (e.g., nb).\n\n- **Brand Promotion:** Consider models that highlight positive sentiments (e.g., svc).\n\n- **Overall Market Analysis:** Choose a model that provides a balanced view (e.g., logit).\n\nIn summary, the selection of the model should be closely tied to the business objectives of the sentiment analysis. Understanding the context, the importance of positive vs. negative sentiments, and the specific use case will guide the final decision. Collaboration with domain experts and further validation can also help in optimizing the model for the desired business outcome.","metadata":{}},{"cell_type":"markdown","source":"# Hyper-parameter Tuning","metadata":{}},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{}},{"cell_type":"code","source":"# # Define the parameter grid\n# param_grid_log = {\n#     'preprocessor__tfidf__max_features': [1000, 5000], # 2 options\n#     'preprocessor__tfidf__ngram_range': [(1, 1)], # 1 option\n#     'logit__penalty': ['l1', 'l2'], # 2 options\n#     'logit__C': [0.1, 1], # 2 options\n#     'logit__fit_intercept': [True, False], # 2 options\n#     'logit__solver': ['liblinear','saga'], # 1 option\n#     'logit__class_weight': [None], # 1 option\n#     'logit__max_iter': [100, 500] # 2 options\n# }\n\n# # Create the grid search object\n# grid_search_log = GridSearchCV(pipe_log, param_grid_log, cv=5, verbose=1, scoring='f1') # You can change the scoring to any other appropriate metric\n\n# # Fit the grid search on the training data\n# grid_search_log.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:23.842453Z","iopub.execute_input":"2023-08-30T06:32:23.842831Z","iopub.status.idle":"2023-08-30T06:32:23.848533Z","shell.execute_reply.started":"2023-08-30T06:32:23.842800Z","shell.execute_reply":"2023-08-30T06:32:23.847283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n\n# # Now you can access the best_params_ and best_estimator_ attributes\n# best_params = grid_search_log.best_params_\n# best_estimator = grid_search_log.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:23.850447Z","iopub.execute_input":"2023-08-30T06:32:23.850816Z","iopub.status.idle":"2023-08-30T06:32:23.870876Z","shell.execute_reply.started":"2023-08-30T06:32:23.850785Z","shell.execute_reply":"2023-08-30T06:32:23.869733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Evaluate the best estimator on the test data\n# score = best_estimator.score(X_test, y_test)\n# score","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:23.872318Z","iopub.execute_input":"2023-08-30T06:32:23.872976Z","iopub.status.idle":"2023-08-30T06:32:23.886059Z","shell.execute_reply.started":"2023-08-30T06:32:23.872940Z","shell.execute_reply":"2023-08-30T06:32:23.884906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#score=0.7901204227082821","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:23.887538Z","iopub.execute_input":"2023-08-30T06:32:23.888092Z","iopub.status.idle":"2023-08-30T06:32:23.903325Z","shell.execute_reply.started":"2023-08-30T06:32:23.888059Z","shell.execute_reply":"2023-08-30T06:32:23.902084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Get the predictions for the test data\n# y_pred = best_estimator.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:23.905109Z","iopub.execute_input":"2023-08-30T06:32:23.905509Z","iopub.status.idle":"2023-08-30T06:32:23.917811Z","shell.execute_reply.started":"2023-08-30T06:32:23.905476Z","shell.execute_reply":"2023-08-30T06:32:23.916600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Print best hyperparameters and classification report\n# print(\"Best Hyperparameters:\", best_params)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:23.922322Z","iopub.execute_input":"2023-08-30T06:32:23.922766Z","iopub.status.idle":"2023-08-30T06:32:23.932389Z","shell.execute_reply.started":"2023-08-30T06:32:23.922735Z","shell.execute_reply":"2023-08-30T06:32:23.930976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Best Hyperparameters: {'logit__C': 1, 'logit__class_weight': None, 'logit__fit_intercept': True, 'logit__max_iter': 100, 'logit__penalty': 'l1', 'logit__solver': 'liblinear', 'preprocessor__tfidf__max_features': 5000, 'preprocessor__tfidf__ngram_range': (1, 1)}","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:23.933941Z","iopub.execute_input":"2023-08-30T06:32:23.934647Z","iopub.status.idle":"2023-08-30T06:32:23.947984Z","shell.execute_reply.started":"2023-08-30T06:32:23.934610Z","shell.execute_reply":"2023-08-30T06:32:23.946844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# report(X_test, y_test, grid_search_log)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:23.949558Z","iopub.execute_input":"2023-08-30T06:32:23.950145Z","iopub.status.idle":"2023-08-30T06:32:23.963128Z","shell.execute_reply.started":"2023-08-30T06:32:23.950111Z","shell.execute_reply":"2023-08-30T06:32:23.961959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Saving the hyper-tuned LogisticRegression model","metadata":{}},{"cell_type":"code","source":"# import pickle\n\n# # Save the model to a file\n# with open('best_logistic_model.pkl', 'wb') as f:\n#     pickle.dump(grid_search_log, f)\n\n# # You can also save the best parameters separately if needed\n# with open('best_logistic_params.pkl', 'wb') as f:\n#     pickle.dump(best_params, f)\n\n# print(\"Model and parameters saved successfully!\")","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:23.965203Z","iopub.execute_input":"2023-08-30T06:32:23.969735Z","iopub.status.idle":"2023-08-30T06:32:23.976808Z","shell.execute_reply.started":"2023-08-30T06:32:23.969689Z","shell.execute_reply":"2023-08-30T06:32:23.975292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load the model from the file\n# with open('best_logistic_model.pkl', 'rb') as f:\n#     loaded_model = pickle.load(f)\n\n# # Load the best parameters from the file\n# with open('best_logistic_params.pkl', 'rb') as f:\n#     loaded_best_params = pickle.load(f)\n\n# # You can now use loaded_model and loaded_best_params in your code\n# print(\"Loaded Best Hyperparameters:\", loaded_best_params)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:23.978362Z","iopub.execute_input":"2023-08-30T06:32:23.978731Z","iopub.status.idle":"2023-08-30T06:32:23.992319Z","shell.execute_reply.started":"2023-08-30T06:32:23.978701Z","shell.execute_reply":"2023-08-30T06:32:23.990929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hypertuning the SVC Model","metadata":{}},{"cell_type":"code","source":"# # Create a calibrated classifier from the LinearSVC\n# calibrated_svc = CalibratedClassifierCV(base_estimator=pipe_svc)\n\n# # Define the parameter grid\n# param_grid_calibrated_svc = {\n#     'base_estimator__preprocessor__tfidf__max_features': [1000, 3000], # Maximum number of features for TF-IDF\n#     'base_estimator__preprocessor__tfidf__ngram_range': [(1, 1), (1, 2)], # Unigrams or bigrams\n#     'base_estimator__svc__C': [0.1, 1, 10], # Regularization parameter\n#     'base_estimator__svc__loss': ['hinge'], # Specifies the loss function\n#     'base_estimator__svc__penalty': ['l2'], # Specifies the norm used in the penalization\n#     'base_estimator__svc__fit_intercept': [True], # Specifies if a constant should be added to the decision function\n#     'base_estimator__svc__max_iter': [1000], # Maximum number of iterations for the solvers to converge\n#     'base_estimator__svc__class_weight': [None], # Weights associated with classes\n#     'base_estimator__svc__multi_class': ['ovr'] # Determines the multi-class strategy\n# }\n\n\n# # Create the grid search object\n# grid_calibrated_svc = GridSearchCV(calibrated_svc, param_grid_calibrated_svc, cv=5, verbose=1, scoring='f1') # You can change the scoring to any other appropriate metric\n\n# # Fit the grid search on the training data\n# grid_calibrated_svc.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:23.997012Z","iopub.execute_input":"2023-08-30T06:32:23.997648Z","iopub.status.idle":"2023-08-30T06:32:24.014175Z","shell.execute_reply.started":"2023-08-30T06:32:23.997607Z","shell.execute_reply":"2023-08-30T06:32:24.013225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"Best parameters for Calibrated LinearSVC:\", grid_calibrated_svc.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:24.015575Z","iopub.execute_input":"2023-08-30T06:32:24.016127Z","iopub.status.idle":"2023-08-30T06:32:24.029289Z","shell.execute_reply.started":"2023-08-30T06:32:24.016094Z","shell.execute_reply":"2023-08-30T06:32:24.028041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# score = best_estimator.score(X_test, y_test)\n# score","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:24.030863Z","iopub.execute_input":"2023-08-30T06:32:24.031505Z","iopub.status.idle":"2023-08-30T06:32:24.045034Z","shell.execute_reply.started":"2023-08-30T06:32:24.031471Z","shell.execute_reply":"2023-08-30T06:32:24.043362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# score=0.7901204227082821","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:24.046878Z","iopub.execute_input":"2023-08-30T06:32:24.047649Z","iopub.status.idle":"2023-08-30T06:32:24.060712Z","shell.execute_reply.started":"2023-08-30T06:32:24.047610Z","shell.execute_reply":"2023-08-30T06:32:24.059534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Evaluate the best Calibrated LinearSVC model\n# report(X_test, y_test, grid_calibrated_svc)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:24.062451Z","iopub.execute_input":"2023-08-30T06:32:24.063279Z","iopub.status.idle":"2023-08-30T06:32:24.075248Z","shell.execute_reply.started":"2023-08-30T06:32:24.063231Z","shell.execute_reply":"2023-08-30T06:32:24.073820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Saving the hyper-tuned SVC model","metadata":{}},{"cell_type":"code","source":"# # Save the Calibrated LinearSVC model to a file\n# with open('best_calibrated_svc_model.pkl', 'wb') as f:\n#     pickle.dump(grid_calibrated_svc, f)\n\n# # Save the best parameters of the Calibrated LinearSVC model to a file\n# best_params_calibrated_svc = grid_calibrated_svc.best_params_\n# with open('best_calibrated_svc_params.pkl', 'wb') as f:\n#     pickle.dump(best_params_calibrated_svc, f)\n\n# print(\"Calibrated LinearSVC model and parameters saved successfully!\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:24.077458Z","iopub.execute_input":"2023-08-30T06:32:24.078307Z","iopub.status.idle":"2023-08-30T06:32:24.092550Z","shell.execute_reply.started":"2023-08-30T06:32:24.078269Z","shell.execute_reply":"2023-08-30T06:32:24.091133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load the Calibrated LinearSVC model from the file\n# with open('best_calibrated_svc_model.pkl', 'rb') as f:\n#     loaded_calibrated_svc_model = pickle.load(f)\n\n# # Load the best parameters of the Calibrated LinearSVC model from the file\n# with open('best_calibrated_svc_params.pkl', 'rb') as f:\n#     loaded_best_calibrated_svc_params = pickle.load(f)\n\n# # You can now use loaded_calibrated_svc_model and loaded_best_calibrated_svc_params in your code\n# print(\"Loaded Best Hyperparameters for Calibrated LinearSVC:\", loaded_best_calibrated_svc_params)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:24.094227Z","iopub.execute_input":"2023-08-30T06:32:24.095127Z","iopub.status.idle":"2023-08-30T06:32:24.113473Z","shell.execute_reply.started":"2023-08-30T06:32:24.095078Z","shell.execute_reply":"2023-08-30T06:32:24.112552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loaded Best Hyperparameters for Calibrated LinearSVC: {'base_estimator__preprocessor__tfidf__max_features': 3000, 'base_estimator__preprocessor__tfidf__ngram_range': (1, 1), 'base_estimator__svc__C': 1, 'base_estimator__svc__class_weight': None, 'base_estimator__svc__fit_intercept': True, 'base_estimator__svc__loss': 'hinge', 'base_estimator__svc__max_iter': 1000, 'base_estimator__svc__multi_class': 'ovr', 'base_estimator__svc__penalty': 'l2'}","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:24.115302Z","iopub.execute_input":"2023-08-30T06:32:24.116048Z","iopub.status.idle":"2023-08-30T06:32:24.130054Z","shell.execute_reply.started":"2023-08-30T06:32:24.116013Z","shell.execute_reply":"2023-08-30T06:32:24.129072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary\n### Model summary after Hyper-parameter tuning a couple of models\n\n> The scores went down for both **LogisticRegression** and **LinearSVC**.\n\n> This might be due to several reasons, one being overfitting or choosing unfavourable parameters, further tuning of the parameters is required to arrive at the best set of parameters.\n\n> However on looking at the PR curves for training and test data, it doesn't seem like overfitting is the cause, so an unfavourable set of parameters might be the most likely cause for a lower score after hyper-parameter tuning.\n","metadata":{}},{"cell_type":"markdown","source":"#### Making the submission.csv","metadata":{}},{"cell_type":"code","source":"def submission_csv(y_pred):\n    # Map 1 to 'Positive' and 0 to 'Negative'\n    sentiment_mapping = {1: 'POSITIVE', 0: 'NEGATIVE'}\n    y_pred_labels = [sentiment_mapping[pred] for pred in y_pred]\n\n    # Create a DataFrame with the predicted labels\n    submission = pd.DataFrame({'id': range(len(y_pred_labels)), 'sentiment': y_pred_labels})\n\n    # Save the DataFrame to the submission.csv file\n    submission_file = \"submission.csv\"\n    submission.to_csv(submission_file, index=False)  # Set index=False to remove the index column\n    \n    print(f'{submission_file} has been created successfully')\n    print('Contents of the submission file:')\n    #print(submission)\n    return submission\n\n\n# Create a DataFrame with the required columns\ntest_data_for_submission = merged_test_data[['reviewText', 'audienceScore', 'runtimeMinutes']]\n\n# Make predictions on the actual test dataset for submission\ny_pred_submission = pipe_log.predict(test_data_for_submission)\n\nsubmission_csv(y_pred_submission)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:24.131559Z","iopub.execute_input":"2023-08-30T06:32:24.132200Z","iopub.status.idle":"2023-08-30T06:32:25.508177Z","shell.execute_reply.started":"2023-08-30T06:32:24.132167Z","shell.execute_reply":"2023-08-30T06:32:25.506690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_data","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:25.510439Z","iopub.execute_input":"2023-08-30T06:32:25.510832Z","iopub.status.idle":"2023-08-30T06:32:25.523530Z","shell.execute_reply.started":"2023-08-30T06:32:25.510800Z","shell.execute_reply":"2023-08-30T06:32:25.522541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_submission.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-30T06:32:25.525045Z","iopub.execute_input":"2023-08-30T06:32:25.525697Z","iopub.status.idle":"2023-08-30T06:32:25.535953Z","shell.execute_reply.started":"2023-08-30T06:32:25.525658Z","shell.execute_reply":"2023-08-30T06:32:25.534256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___________________________________________________________________________________________________________________","metadata":{}}]}